"""
Main prompt optimization service combining all AI capabilities.
"""

from typing import Optional, Dict, Any, List
from .capability_analyzer import CapabilityAnalyzer
from ..core.models import CapabilityRecommendation
from ..services.ai_service import AIService


class PromptOptimizer:
    """Main service for optimizing Office automation prompts."""
    
    def __init__(self, target_model_type: str = "big", trust_mode: bool = False):
        self.ai_service = AIService()
        self.analyzer = CapabilityAnalyzer()
        self.target_model_type = target_model_type
        self.trust_mode = trust_mode  # When True, trust big models and minimize optimization
        self.conversation_history: List[Dict[str, str]] = []
        
        # Pre-planned templates for different task types
        self.task_templates = self._initialize_task_templates()
        
        # Target model capabilities
        self.model_types = {
            "big": {
                "name": "Big Model (GPT-4, Claude-3.5, etc.)",
                "prompt_style": "comprehensive, detailed, information-preserving",
                "max_detail": "maximum",
                "context_preservation": "full",
                "information_loss_tolerance": "zero"
            },
            "small": {
                "name": "Small Model (7B, 13B models, etc.)",
                "prompt_style": "detailed, step-by-step, explicit instructions", 
                "max_detail": "high",
                "context_preservation": "essential",
                "information_loss_tolerance": "minimal"
            }
        }
    
    def set_target_model(self, model_type: str) -> str:
        """Set target model type and return confirmation message."""
        if model_type not in self.model_types:
            return "Invalid model type. Use 'big' or 'small'."
        
        self.target_model_type = model_type
        model_name = self.model_types[model_type]["name"]
        
        if model_type == "big":
            return f"ğŸ¤– Switched to big model mode: {model_name}\\nPrompts will be more brief, relying on model reasoning"
        else:
            return f"ğŸ¤– Switched to small model mode: {model_name}\\nPrompts will be more detailed with explicit steps"
    
    def clear_conversation(self) -> str:
        """Clear conversation history."""
        self.conversation_history = []
        return "ğŸ§¹ Conversation cleared! Starting fresh with new memory."
    
    def add_to_history(self, role: str, content: str):
        """Add message to conversation history."""
        self.conversation_history.append({"role": role, "content": content})
    
    def _extract_key_information(self, messages: List[Dict[str, str]]) -> str:
        """Extract key information from earlier messages to preserve important context."""
        key_info = []
        
        for msg in messages:
            content = msg['content'].lower()
            role = msg['role']
            
            # Extract important keywords and patterns
            if role == 'user':
                # Look for task requirements, constraints, specific needs
                if any(keyword in content for keyword in ['requirement', 'need', 'must', 'should', 'requirement']):
                    key_info.append(f"Requirement: {msg['content'][:100]}...")
                elif any(keyword in content for keyword in ['error', 'problem', 'issue', 'bug']):
                    key_info.append(f"Issue: {msg['content'][:100]}...")
                elif any(keyword in content for keyword in ['target', 'goal', 'objective', 'purpose']):
                    key_info.append(f"Goal: {msg['content'][:100]}...")
            elif role == 'assistant':
                # Look for important decisions or recommendations
                if any(keyword in content for keyword in ['recommend', 'suggest', 'solution', 'approach']):
                    key_info.append(f"Recommendation: {msg['content'][:100]}...")
        
        return "; ".join(key_info) if key_info else ""
    
    def _get_domain_specific_guidance(self, capability_reason: str, is_chinese: bool) -> str:
        """Generate domain-specific guidance based on the type of fuzzy task."""
        guidance_templates = {
            "complex_data_cleaning": {
                "chinese": """
ğŸ”§ æ•°æ®æ¸…ç†ä¸“é¡¹æŒ‡å¯¼ï¼š
â€¢ æ•°æ®æ ‡å‡†åŒ–ï¼šç»Ÿä¸€æ ¼å¼ã€ç¼–ç ã€å‘½åçº¦å®š
â€¢ é‡å¤é¡¹å¤„ç†ï¼šè¯†åˆ«å¹¶åˆå¹¶ç›¸ä¼¼è®°å½•
â€¢ ç¼ºå¤±å€¼ç­–ç•¥ï¼šå¡«å……ã€æ’å€¼æˆ–æ ‡è®°å¤„ç†
â€¢ å¼‚å¸¸å€¼æ£€æµ‹ï¼šè¯†åˆ«å¹¶å¤„ç†è¶…å‡ºæ­£å¸¸èŒƒå›´çš„æ•°æ®
â€¢ ä¸€è‡´æ€§æ£€æŸ¥ï¼šç¡®ä¿è·¨å­—æ®µçš„æ•°æ®é€»è¾‘ä¸€è‡´æ€§""",
                "english": """
ğŸ”§ Data Cleaning Specialized Guidance:
â€¢ Data Standardization: Unify formats, encoding, naming conventions
â€¢ Duplicate Handling: Identify and merge similar records
â€¢ Missing Value Strategy: Fill, interpolate, or flag for processing
â€¢ Outlier Detection: Identify and handle data outside normal ranges
â€¢ Consistency Checks: Ensure logical consistency across fields"""
            },
            "intelligent_extraction": {
                "chinese": """
ğŸ” æ™ºèƒ½æå–ä¸“é¡¹æŒ‡å¯¼ï¼š
â€¢ æ¨¡å¼è¯†åˆ«ï¼šè¯†åˆ«æ•°æ®ä¸­çš„éšè—æ¨¡å¼å’Œç»“æ„
â€¢ å®ä½“æŠ½å–ï¼šä»æ–‡æœ¬ä¸­æå–äººåã€åœ°å€ã€æ—¥æœŸç­‰
â€¢ å…³ç³»æ˜ å°„ï¼šå»ºç«‹æ•°æ®å…ƒç´ ä¹‹é—´çš„é€»è¾‘å…³ç³»
â€¢ ä¸Šä¸‹æ–‡ç†è§£ï¼šåŸºäºè¯­å¢ƒæ¨æ–­ç¼ºå¤±æˆ–æ¨¡ç³Šä¿¡æ¯
â€¢ è¯­ä¹‰åˆ†æï¼šç†è§£æ–‡æœ¬å†…å®¹çš„æ·±å±‚å«ä¹‰""",
                "english": """
ğŸ” Intelligent Extraction Specialized Guidance:
â€¢ Pattern Recognition: Identify hidden patterns and structures in data
â€¢ Entity Extraction: Extract names, addresses, dates from text
â€¢ Relationship Mapping: Establish logical relationships between data elements
â€¢ Context Understanding: Infer missing or ambiguous information from context
â€¢ Semantic Analysis: Understand deeper meaning of text content"""
            },
            "contextual_processing": {
                "chinese": """
ğŸ§  ä¸Šä¸‹æ–‡å¤„ç†ä¸“é¡¹æŒ‡å¯¼ï¼š
â€¢ è¯­å¢ƒåˆ†æï¼šç†è§£æ•°æ®åœ¨ç‰¹å®šç¯å¢ƒä¸­çš„å«ä¹‰
â€¢ æ­§ä¹‰æ¶ˆè§£ï¼šåŸºäºä¸Šä¸‹æ–‡ç¡®å®šå¤šä¹‰è¯çš„æ­£ç¡®å«ä¹‰
â€¢ æ¨ç†è¡¥å…¨ï¼šæ ¹æ®å·²çŸ¥ä¿¡æ¯æ¨æ–­ç¼ºå¤±éƒ¨åˆ†
â€¢ æ–‡åŒ–é€‚åº”ï¼šå¤„ç†ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹çš„æ•°æ®å·®å¼‚
â€¢ åŠ¨æ€é€‚åº”ï¼šæ ¹æ®æ•°æ®ç‰¹ç‚¹è°ƒæ•´å¤„ç†ç­–ç•¥""",
                "english": """
ğŸ§  Contextual Processing Specialized Guidance:
â€¢ Context Analysis: Understand data meaning in specific environments
â€¢ Ambiguity Resolution: Determine correct meaning based on context
â€¢ Inference Completion: Infer missing parts from known information
â€¢ Cultural Adaptation: Handle data differences across cultural backgrounds
â€¢ Dynamic Adaptation: Adjust processing strategy based on data characteristics"""
            },
            "adaptive_tasks": {
                "chinese": """
ğŸ”„ è‡ªé€‚åº”å¤„ç†ä¸“é¡¹æŒ‡å¯¼ï¼š
â€¢ çµæ´»è§„åˆ™ï¼šæ ¹æ®æ•°æ®ç‰¹ç‚¹åŠ¨æ€è°ƒæ•´å¤„ç†è§„åˆ™
â€¢ ä¾‹å¤–å¤„ç†ï¼šä¸ºç‰¹æ®Šæƒ…å†µè®¾è®¡ä¸“é—¨çš„å¤„ç†é€»è¾‘
â€¢ å­¦ä¹ é€‚åº”ï¼šä»å¤„ç†ç»“æœä¸­å­¦ä¹ å¹¶ä¼˜åŒ–ç­–ç•¥
â€¢ æ¸è¿›å¤„ç†ï¼šåˆ†æ­¥éª¤å¤„ç†å¤æ‚ä»»åŠ¡ï¼Œé€æ­¥å®Œå–„
â€¢ åé¦ˆå¾ªç¯ï¼šåŸºäºéªŒè¯ç»“æœè°ƒæ•´å¤„ç†æ–¹æ³•""",
                "english": """
ğŸ”„ Adaptive Processing Specialized Guidance:
â€¢ Flexible Rules: Dynamically adjust processing rules based on data characteristics
â€¢ Exception Handling: Design specialized logic for special cases
â€¢ Learning Adaptation: Learn from processing results and optimize strategy
â€¢ Progressive Processing: Handle complex tasks step-by-step, gradually refine
â€¢ Feedback Loop: Adjust processing methods based on validation results"""
            },
            "reasoning_required": {
                "chinese": """
ğŸ¤” æ¨ç†å†³ç­–ä¸“é¡¹æŒ‡å¯¼ï¼š
â€¢ é€»è¾‘æ¨ç†ï¼šåŸºäºå·²çŸ¥äº‹å®è¿›è¡Œé€»è¾‘æ¨å¯¼
â€¢ æƒé‡è¯„ä¼°ï¼šä¸ºä¸åŒåˆ¤æ–­æ ‡å‡†åˆ†é…åˆç†æƒé‡
â€¢ å†³ç­–æ ‘ï¼šæ„å»ºç³»ç»ŸåŒ–çš„å†³ç­–æµç¨‹
â€¢ ä¸ç¡®å®šæ€§å¤„ç†ï¼šåœ¨ä¿¡æ¯ä¸å®Œæ•´æ—¶åšå‡ºæœ€ä½³åˆ¤æ–­
â€¢ ç½®ä¿¡åº¦è¯„ä¼°ï¼šä¸ºæ¯ä¸ªå†³ç­–æä¾›å¯ä¿¡åº¦è¯„åˆ†""",
                "english": """
ğŸ¤” Reasoning & Decision Specialized Guidance:
â€¢ Logical Reasoning: Perform logical deduction based on known facts
â€¢ Weight Assessment: Assign reasonable weights to different judgment criteria
â€¢ Decision Tree: Build systematic decision-making processes
â€¢ Uncertainty Handling: Make optimal judgments with incomplete information
â€¢ Confidence Assessment: Provide confidence scores for each decision"""
            }
        }
        
        template = guidance_templates.get(capability_reason, {})
        return template.get("chinese" if is_chinese else "english", "")
    
    def _analyze_hybrid_task(self, user_input: str, capability: 'CapabilityRecommendation', is_chinese: bool) -> str:
        """Provide intelligent analysis for hybrid tasks instead of asking for more details."""
        user_lower = user_input.lower()
        user_task_prefix = f"Task: '{user_input}'\\n\\n" if len(user_input) < 100 else f"Task: '{user_input[:97]}...'\\n\\n"
        
        # Analyze task complexity and provide specific recommendations
        data_volume_indicators = ["æ‰¹é‡", "å¤šä¸ª", "æ‰€æœ‰", "å…¨éƒ¨", "batch", "multiple", "all", "bulk"]
        has_volume = any(indicator in user_lower for indicator in data_volume_indicators)
        
        precision_indicators = ["ç²¾ç¡®", "å‡†ç¡®", "ä¸€è‡´", "æ ‡å‡†åŒ–", "precise", "accurate", "consistent", "standardize"]
        needs_precision = any(indicator in user_lower for indicator in precision_indicators)
        
        content_indicators = ["å†…å®¹", "æ–‡æœ¬", "ä¿¡æ¯", "æè¿°", "content", "text", "information", "description"]
        has_content_work = any(indicator in user_lower for indicator in content_indicators)
        
        extraction_indicators = ["æå–", "æŠ½å–", "è·å–", "åˆ†ç¦»", "extract", "parse", "separate", "split"]
        needs_extraction = any(indicator in user_lower for indicator in extraction_indicators)
        
        # Make intelligent decision based on task characteristics
        if has_volume and needs_precision:
            # High volume + precision = VBA preferred
            recommendation = "VBA"
            reason = "æ‰¹é‡ç²¾ç¡®å¤„ç†" if is_chinese else "batch precision processing"
        elif has_content_work and not needs_extraction:
            # Content work without extraction = AI preferred  
            recommendation = "AI"
            reason = "å†…å®¹ç†è§£å¤„ç†" if is_chinese else "content understanding processing"
        elif needs_extraction and has_volume:
            # Extraction + volume = Hybrid approach
            recommendation = "HYBRID_STRUCTURED"
            reason = "ç»“æ„åŒ–æå–å¤„ç†" if is_chinese else "structured extraction processing"
        else:
            # Default to AI for ambiguous cases
            recommendation = "AI"
            reason = "æ™ºèƒ½åˆ†æå¤„ç†" if is_chinese else "intelligent analysis processing"
        
        if is_chinese:
            if recommendation == "VBA":
                return f"""{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel
ğŸ”§ æ¨èæ–¹æ¡ˆï¼šVBAè‡ªåŠ¨åŒ–å¤„ç†
ğŸ“Š åˆ†æç»“æœï¼š{reason}

ğŸ’¡ ç†ç”±åˆ†æï¼š
- ä»»åŠ¡æ¶‰åŠå¤§é‡æ•°æ®æˆ–éœ€è¦ç²¾ç¡®æ“ä½œ
- VBAèƒ½æä¾›å¯é çš„æ‰¹é‡å¤„ç†èƒ½åŠ›
- é€‚åˆæ ‡å‡†åŒ–ã€é‡å¤æ€§æ“ä½œ

ğŸ¯ å®æ–½å»ºè®®ï¼š
1. ä½¿ç”¨VBAå®è¿›è¡Œæ‰¹é‡è‡ªåŠ¨åŒ–
2. è®¾è®¡é”™è¯¯å¤„ç†å’ŒéªŒè¯æœºåˆ¶
3. ç¡®ä¿æ•°æ®ä¸€è‡´æ€§å’Œå‡†ç¡®æ€§

å…·ä½“å®ç°ï¼šåŸºäºä»»åŠ¡ç‰¹ç‚¹è®¾è®¡VBAè§£å†³æ–¹æ¡ˆ"""
            
            elif recommendation == "AI":
                return f"""{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel
âœ… æ¨èæ–¹æ¡ˆï¼šAIæ™ºèƒ½å¤„ç†
ğŸ§  åˆ†æç»“æœï¼š{reason}

ğŸ’¡ ç†ç”±åˆ†æï¼š
- ä»»åŠ¡éœ€è¦å†…å®¹ç†è§£æˆ–ä¸Šä¸‹æ–‡åˆ†æ
- AIèƒ½å¤„ç†å¤æ‚çš„è¯­ä¹‰å’Œé€»è¾‘å…³ç³»
- é€‚åˆçµæ´»æ€§å’Œé€‚åº”æ€§è¦æ±‚é«˜çš„åœºæ™¯

ğŸ¯ å®æ–½å»ºè®®ï¼š
1. åˆ©ç”¨AIçš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›
2. ç»“åˆä¸Šä¸‹æ–‡è¿›è¡Œæ™ºèƒ½åˆ¤æ–­
3. å¤„ç†ä¸è§„åˆ™æˆ–å˜åŒ–çš„æ•°æ®æ ¼å¼

å…·ä½“å®ç°ï¼šè®¾è®¡AIè¾…åŠ©çš„æ™ºèƒ½å¤„ç†æµç¨‹"""
            
            else:  # HYBRID_STRUCTURED
                return f"""{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel
ğŸ”€ æ¨èæ–¹æ¡ˆï¼šAI+VBAæ··åˆå¤„ç†
âš™ï¸ åˆ†æç»“æœï¼š{reason}

ğŸ’¡ ç†ç”±åˆ†æï¼š
- ä»»åŠ¡åŒæ—¶éœ€è¦æ™ºèƒ½ç†è§£å’Œæ‰¹é‡å¤„ç†
- AIè´Ÿè´£å¤æ‚åˆ†æï¼ŒVBAè´Ÿè´£æ‰§è¡Œæ“ä½œ
- ç»“åˆä¸¤è€…ä¼˜åŠ¿å®ç°æœ€ä½³æ•ˆæœ

ğŸ¯ å®æ–½å»ºè®®ï¼š
1. AIéƒ¨åˆ†ï¼šç†è§£å†…å®¹ã€è¯†åˆ«æ¨¡å¼ã€å¤„ç†å¼‚å¸¸
2. VBAéƒ¨åˆ†ï¼šæ‰¹é‡æ“ä½œã€æ•°æ®è½¬æ¢ã€æ ¼å¼åŒ–
3. ååŒå·¥ä½œï¼šAIåˆ†æç»“æœæŒ‡å¯¼VBAæ‰§è¡Œ

å…·ä½“å®ç°ï¼šè®¾è®¡AIåˆ†æ+VBAæ‰§è¡Œçš„ååŒæ–¹æ¡ˆ"""
        
        else:  # English
            if recommendation == "VBA":
                return f"""{user_task_prefix}App: 0=Word, 1=Excel
ğŸ”§ Recommended Solution: VBA Automation
ğŸ“Š Analysis Result: {reason}

ğŸ’¡ Reasoning:
- Task involves high volume or requires precise operations
- VBA provides reliable batch processing capabilities
- Suitable for standardized, repetitive operations

ğŸ¯ Implementation Approach:
1. Use VBA macros for batch automation
2. Design error handling and validation mechanisms
3. Ensure data consistency and accuracy

Specific Implementation: Design VBA solution based on task characteristics"""
            
            elif recommendation == "AI":
                return f"""{user_task_prefix}App: 0=Word, 1=Excel
âœ… Recommended Solution: AI Intelligence Processing
ğŸ§  Analysis Result: {reason}

ğŸ’¡ Reasoning:
- Task requires content understanding or contextual analysis
- AI can handle complex semantic and logical relationships
- Suitable for scenarios requiring high flexibility and adaptability

ğŸ¯ Implementation Approach:
1. Leverage AI's natural language understanding capabilities
2. Combine context for intelligent judgment
3. Handle irregular or variable data formats

Specific Implementation: Design AI-assisted intelligent processing workflow"""
            
            else:  # HYBRID_STRUCTURED
                return f"""{user_task_prefix}App: 0=Word, 1=Excel
ğŸ”€ Recommended Solution: AI+VBA Hybrid Processing
âš™ï¸ Analysis Result: {reason}

ğŸ’¡ Reasoning:
- Task requires both intelligent understanding and batch processing
- AI handles complex analysis, VBA handles execution
- Combines advantages of both approaches for optimal results

ğŸ¯ Implementation Approach:
1. AI Component: Understand content, identify patterns, handle exceptions
2. VBA Component: Batch operations, data transformation, formatting
3. Collaborative Work: AI analysis guides VBA execution

Specific Implementation: Design collaborative AI analysis + VBA execution solution"""
    
    def _evaluate_trust_mode(self, user_input: str) -> Dict[str, str]:
        """Evaluate whether to trust big model, pass through, or ask clarifying questions."""
        user_lower = user_input.lower()
        is_chinese = any('\u4e00' <= char <= '\u9fff' for char in user_input)
        
        # Check if request is clear and complete
        completeness_indicators = {
            "has_clear_action": any(word in user_lower for word in [
                "create", "generate", "extract", "format", "calculate", "convert", "analyze",
                "åˆ›å»º", "ç”Ÿæˆ", "æå–", "æ ¼å¼åŒ–", "è®¡ç®—", "è½¬æ¢", "åˆ†æ", "åˆ¶ä½œ", "å¤„ç†"
            ]),
            "has_target_object": any(word in user_lower for word in [
                "table", "document", "file", "data", "report", "chart", "list",
                "è¡¨æ ¼", "æ–‡æ¡£", "æ–‡ä»¶", "æ•°æ®", "æŠ¥å‘Š", "å›¾è¡¨", "åˆ—è¡¨", "å†…å®¹"
            ]),
            "has_specific_details": len(user_input.split()) > 5,  # More than 5 words suggests detail
            "has_context": len(self.conversation_history) > 2  # Has conversation context
        }
        
        completeness_score = sum(completeness_indicators.values())
        
        # Check for ambiguity indicators
        ambiguity_indicators = [
            "help", "assist", "ä»€ä¹ˆ", "å¦‚ä½•", "æ€ä¹ˆ", "å¸®åŠ©", "ååŠ©",
            "best way", "æœ€å¥½çš„", "æœ€ä½³", "å»ºè®®", "recommend", "suggest"
        ]
        has_ambiguity = any(indicator in user_lower for indicator in ambiguity_indicators)
        
        # Check for missing critical information
        missing_info_patterns = {
            "vague_object": any(word in user_lower for word in ["this", "that", "å®ƒ", "è¿™ä¸ª", "é‚£ä¸ª"]) and not completeness_indicators["has_target_object"],
            "unclear_scope": any(word in user_lower for word in ["some", "few", "several", "ä¸€äº›", "å‡ ä¸ª", "éƒ¨åˆ†"]),
            "missing_format": "format" in user_lower or "æ ¼å¼" in user_lower and not any(fmt in user_lower for fmt in ["xlsx", "docx", "pdf", "csv", "txt"]),
            "missing_location": any(word in user_lower for word in ["where", "å“ªé‡Œ", "ä½ç½®"]) and not any(loc in user_lower for loc in ["column", "row", "cell", "åˆ—", "è¡Œ", "å•å…ƒæ ¼"])
        }
        
        has_missing_info = any(missing_info_patterns.values())
        
        # Decision logic
        if completeness_score >= 3 and not has_ambiguity and not has_missing_info:
            # Clear, complete request - trust the big model
            return {"action": "pass_through"}
        
        elif has_ambiguity or has_missing_info:
            # Generate intelligent clarifying questions
            questions = self._generate_clarifying_questions(user_input, missing_info_patterns, is_chinese)
            return {"action": "clarify", "response": questions}
        
        else:
            # Moderate clarity - trust big model but with context
            return {"action": "pass_through"}
    
    def _generate_clarifying_questions(self, user_input: str, missing_patterns: Dict[str, bool], is_chinese: bool) -> str:
        """Generate intelligent clarifying questions to improve the prompt."""
        questions = []
        
        if missing_patterns.get("vague_object"):
            if is_chinese:
                questions.append("ğŸ¯ è¯·æ˜ç¡®å…·ä½“çš„æ“ä½œå¯¹è±¡ï¼ˆå¦‚ï¼šå“ªä¸ªè¡¨æ ¼ã€æ–‡æ¡£æˆ–æ•°æ®é›†ï¼‰")
            else:
                questions.append("ğŸ¯ Please specify the exact object (e.g., which table, document, or dataset)")
        
        if missing_patterns.get("unclear_scope"):
            if is_chinese:
                questions.append("ğŸ“Š è¯·è¯´æ˜å¤„ç†èŒƒå›´ï¼ˆå¦‚ï¼šæ‰€æœ‰æ•°æ®ã€ç‰¹å®šæ¡ä»¶çš„æ•°æ®ã€è¿˜æ˜¯æ ·ä¾‹æ•°æ®ï¼‰")
            else:
                questions.append("ğŸ“Š Please clarify the scope (e.g., all data, data meeting specific conditions, or sample data)")
        
        if missing_patterns.get("missing_format"):
            if is_chinese:
                questions.append("ğŸ“„ è¯·æŒ‡å®šè¾“å‡ºæ ¼å¼æˆ–æ–‡ä»¶ç±»å‹ï¼ˆå¦‚ï¼šExcelã€Wordã€PDFç­‰ï¼‰")
            else:
                questions.append("ğŸ“„ Please specify output format or file type (e.g., Excel, Word, PDF, etc.)")
        
        if missing_patterns.get("missing_location"):
            if is_chinese:
                questions.append("ğŸ“ è¯·æ˜ç¡®æ•°æ®ä½ç½®æˆ–ç›®æ ‡ä½ç½®ï¼ˆå¦‚ï¼šå…·ä½“åˆ—åã€è¡Œå·ã€å•å…ƒæ ¼èŒƒå›´ï¼‰")
            else:
                questions.append("ğŸ“ Please specify data location or target location (e.g., specific column names, row numbers, cell ranges)")
        
        # If no specific missing patterns detected, ask general clarifying questions
        if not questions:
            if is_chinese:
                questions.append("ğŸ’¡ ä¸ºäº†æä¾›æœ€å‡†ç¡®çš„è§£å†³æ–¹æ¡ˆï¼Œè¯·è¡¥å……ï¼š\n- å…·ä½“çš„æ“ä½œç›®æ ‡å’ŒæœŸæœ›ç»“æœ\n- æ•°æ®çš„æ¥æºå’Œæ ¼å¼\n- ä»»ä½•ç‰¹æ®Šè¦æ±‚æˆ–é™åˆ¶æ¡ä»¶")
            else:
                questions.append("ğŸ’¡ To provide the most accurate solution, please add:\n- Specific operation goals and expected results\n- Data source and format\n- Any special requirements or constraints")
        
        # Format the response
        task_summary = f"Task: '{user_input}'\n\n" if len(user_input) < 100 else f"Task: '{user_input[:97]}...'\n\n"
        
        if is_chinese:
            header = f"{task_summary}ğŸ¤” ä¸ºäº†æ›´å¥½åœ°ååŠ©æ‚¨ï¼Œéœ€è¦æ¾„æ¸…ä»¥ä¸‹ä¿¡æ¯ï¼š\n\n"
            footer = "\n\nâœ¨ æä¾›è¿™äº›ç»†èŠ‚åï¼Œæˆ‘å¯ä»¥ä¸ºæ‚¨è®¾è®¡æœ€ä¼˜çš„è§£å†³æ–¹æ¡ˆï¼"
        else:
            header = f"{task_summary}ğŸ¤” To better assist you, I need to clarify the following:\n\n"
            footer = "\n\nâœ¨ Once you provide these details, I can design the optimal solution for you!"
        
        return header + "\n".join(questions) + footer
    
    def _initialize_task_templates(self) -> Dict[str, Dict]:
        """Initialize pre-planned templates for different task types."""
        return {
            "data_extraction": {
                "chinese": {
                    "title": "æ•°æ®æå–ä»»åŠ¡æ¨¡æ¿",
                    "structure": """
åº”ç”¨é€‰æ‹©ï¼š{app_selection}

ğŸ“‹ æ•°æ®æå–æ‰§è¡Œè®¡åˆ’ï¼š

ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼š
- æºæ•°æ®ï¼š{source_data}
- ç›®æ ‡å­—æ®µï¼š{target_fields}
- æå–æ¡ä»¶ï¼š{extraction_conditions}

âš™ï¸ æ‰§è¡Œæ­¥éª¤ï¼š
1. æ•°æ®è¯†åˆ«å’ŒéªŒè¯
   - æ£€æŸ¥æºæ•°æ®æ ¼å¼å’Œå®Œæ•´æ€§
   - ç¡®è®¤å­—æ®µä½ç½®å’Œæ•°æ®ç±»å‹
   
2. æå–é€»è¾‘å®ç°
   - {extraction_method}
   - å¤„ç†è¾¹ç•Œæƒ…å†µå’Œå¼‚å¸¸å€¼
   
3. ç»“æœéªŒè¯å’Œè¾“å‡º
   - éªŒè¯æå–ç»“æœçš„å‡†ç¡®æ€§
   - æ ¼å¼åŒ–å¹¶ä¿å­˜åˆ°ç›®æ ‡ä½ç½®

ğŸ’¡ æŠ€æœ¯å®ç°ï¼š
{technical_implementation}

âœ… éªŒè¯æ£€æŸ¥ï¼š
- æå–æ•°é‡æ˜¯å¦æ­£ç¡®
- æ•°æ®æ ¼å¼æ˜¯å¦ä¸€è‡´
- æ˜¯å¦æœ‰é—æ¼æˆ–é”™è¯¯
""",
                    "placeholders": {
                        "app_selection": "0=Word, 1=Excel",
                        "source_data": "[è¯·å¡«å†™æºæ•°æ®ä½ç½®å’Œæ ¼å¼]",
                        "target_fields": "[è¯·å¡«å†™ç›®æ ‡å­—æ®µåç§°]", 
                        "extraction_conditions": "[è¯·å¡«å†™æå–æ¡ä»¶]",
                        "extraction_method": "[è¯·å¡«å†™å…·ä½“æå–æ–¹æ³•]",
                        "technical_implementation": "[è¯·å¡«å†™æŠ€æœ¯å®ç°æ–¹æ¡ˆ]"
                    }
                },
                "english": {
                    "title": "Data Extraction Task Template",
                    "structure": """
App Selection: {app_selection}

ğŸ“‹ Data Extraction Execution Plan:

ğŸ¯ Task Objective:
- Source Data: {source_data}
- Target Fields: {target_fields}
- Extraction Conditions: {extraction_conditions}

âš™ï¸ Execution Steps:
1. Data Identification and Validation
   - Check source data format and completeness
   - Confirm field positions and data types
   
2. Extraction Logic Implementation
   - {extraction_method}
   - Handle edge cases and outliers
   
3. Result Validation and Output
   - Validate extraction accuracy
   - Format and save to target location

ğŸ’¡ Technical Implementation:
{technical_implementation}

âœ… Validation Checks:
- Is extraction count correct?
- Is data format consistent?
- Any missing or erroneous data?
"""
                }
            },
            
            "content_generation": {
                "chinese": {
                    "title": "å†…å®¹ç”Ÿæˆä»»åŠ¡æ¨¡æ¿",
                    "structure": """
åº”ç”¨é€‰æ‹©ï¼š{app_selection}

ğŸ“‹ å†…å®¹ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼š

ğŸ¯ å†…å®¹è¦æ±‚ï¼š
- å†…å®¹ç±»å‹ï¼š{content_type}
- ç›®æ ‡å—ä¼—ï¼š{target_audience}
- å­—æ•°è¦æ±‚ï¼š{word_count}
- é£æ ¼è¦æ±‚ï¼š{style_requirements}

âš™ï¸ ç”Ÿæˆç»“æ„ï¼š
1. å†…å®¹æ¡†æ¶è®¾è®¡
   - ä¸»è¦ç« èŠ‚ï¼š{main_sections}
   - é€»è¾‘é¡ºåºï¼š{logical_order}
   
2. å†…å®¹åˆ›ä½œæ‰§è¡Œ
   - {content_creation_method}
   - ç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§å’Œè¿è´¯æ€§
   
3. æ ¼å¼åŒ–å’Œç¾åŒ–
   - åº”ç”¨é€‚å½“çš„æ ¼å¼å’Œæ ·å¼
   - æ·»åŠ å¿…è¦çš„å›¾è¡¨æˆ–è§†è§‰å…ƒç´ 

ğŸ’¡ åˆ›ä½œæŒ‡å¯¼ï¼š
{creation_guidance}

âœ… è´¨é‡æ£€æŸ¥ï¼š
- å†…å®¹æ˜¯å¦ç¬¦åˆè¦æ±‚
- é€»è¾‘æ˜¯å¦æ¸…æ™°è¿è´¯
- æ ¼å¼æ˜¯å¦è§„èŒƒç¾è§‚
""",
                    "placeholders": {
                        "app_selection": "0=Word, 1=Excel",
                        "content_type": "[è¯·å¡«å†™å†…å®¹ç±»å‹]",
                        "target_audience": "[è¯·å¡«å†™ç›®æ ‡å—ä¼—]",
                        "word_count": "[è¯·å¡«å†™å­—æ•°è¦æ±‚]",
                        "style_requirements": "[è¯·å¡«å†™é£æ ¼è¦æ±‚]",
                        "main_sections": "[è¯·å¡«å†™ä¸»è¦ç« èŠ‚]",
                        "logical_order": "[è¯·å¡«å†™é€»è¾‘é¡ºåº]",
                        "content_creation_method": "[è¯·å¡«å†™åˆ›ä½œæ–¹æ³•]",
                        "creation_guidance": "[è¯·å¡«å†™åˆ›ä½œæŒ‡å¯¼]"
                    }
                }
            },
            
            "data_processing": {
                "chinese": {
                    "title": "æ•°æ®å¤„ç†ä»»åŠ¡æ¨¡æ¿", 
                    "structure": """
åº”ç”¨é€‰æ‹©ï¼š{app_selection}

ğŸ“‹ æ•°æ®å¤„ç†æ‰§è¡Œè®¡åˆ’ï¼š

ğŸ¯ å¤„ç†ç›®æ ‡ï¼š
- è¾“å…¥æ•°æ®ï¼š{input_data}
- å¤„ç†æ“ä½œï¼š{processing_operations}
- è¾“å‡ºè¦æ±‚ï¼š{output_requirements}

âš™ï¸ å¤„ç†æµç¨‹ï¼š
1. æ•°æ®é¢„å¤„ç†
   - æ•°æ®æ¸…æ´—ï¼š{data_cleaning}
   - æ ¼å¼æ ‡å‡†åŒ–ï¼š{format_standardization}
   
2. æ ¸å¿ƒå¤„ç†é€»è¾‘
   - {core_processing_logic}
   - é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æƒ…å†µ
   
3. ç»“æœæ•´ç†å’ŒéªŒè¯
   - æ•°æ®éªŒè¯å’Œè´¨é‡æ£€æŸ¥
   - æ ¼å¼åŒ–è¾“å‡ºç»“æœ

ğŸ’¡ æŠ€æœ¯æ–¹æ¡ˆï¼š
{technical_solution}

âœ… éªŒè¯æ ‡å‡†ï¼š
- æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
- å¤„ç†ç»“æœå‡†ç¡®æ€§
- è¾“å‡ºæ ¼å¼ç¬¦åˆè¦æ±‚
""",
                    "placeholders": {
                        "app_selection": "0=Word, 1=Excel",
                        "input_data": "[è¯·å¡«å†™è¾“å…¥æ•°æ®æè¿°]",
                        "processing_operations": "[è¯·å¡«å†™å¤„ç†æ“ä½œ]",
                        "output_requirements": "[è¯·å¡«å†™è¾“å‡ºè¦æ±‚]",
                        "data_cleaning": "[è¯·å¡«å†™æ•°æ®æ¸…æ´—æ–¹æ³•]",
                        "format_standardization": "[è¯·å¡«å†™æ ¼å¼æ ‡å‡†åŒ–]",
                        "core_processing_logic": "[è¯·å¡«å†™æ ¸å¿ƒå¤„ç†é€»è¾‘]",
                        "technical_solution": "[è¯·å¡«å†™æŠ€æœ¯æ–¹æ¡ˆ]"
                    }
                }
            },
            
            "automation_task": {
                "chinese": {
                    "title": "è‡ªåŠ¨åŒ–ä»»åŠ¡æ¨¡æ¿",
                    "structure": """
åº”ç”¨é€‰æ‹©ï¼š{app_selection}

ğŸ“‹ è‡ªåŠ¨åŒ–æ‰§è¡Œè®¡åˆ’ï¼š

ğŸ¯ è‡ªåŠ¨åŒ–ç›®æ ‡ï¼š
- é‡å¤æ“ä½œï¼š{repetitive_operations}
- è§¦å‘æ¡ä»¶ï¼š{trigger_conditions}
- æ‰§è¡Œé¢‘ç‡ï¼š{execution_frequency}

âš™ï¸ è‡ªåŠ¨åŒ–æµç¨‹ï¼š
1. è§¦å‘æ¡ä»¶æ£€æµ‹
   - æ¡ä»¶ç›‘æ§ï¼š{condition_monitoring}
   - è§¦å‘åˆ¤æ–­é€»è¾‘ï¼š{trigger_logic}
   
2. è‡ªåŠ¨åŒ–æ‰§è¡Œ
   - {automation_execution}
   - é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
   
3. ç»“æœåé¦ˆå’Œæ—¥å¿—
   - æ‰§è¡ŒçŠ¶æ€è®°å½•
   - ç»“æœé€šçŸ¥å’ŒæŠ¥å‘Š

ğŸ’¡ å®ç°æ–¹æ¡ˆï¼š
{implementation_plan}

âœ… ç›‘æ§æŒ‡æ ‡ï¼š
- æ‰§è¡ŒæˆåŠŸç‡
- å¤„ç†æ—¶é—´æ•ˆç‡
- é”™è¯¯ç±»å‹å’Œé¢‘ç‡
""",
                    "placeholders": {
                        "app_selection": "0=Word, 1=Excel",
                        "repetitive_operations": "[è¯·å¡«å†™é‡å¤æ“ä½œå†…å®¹]",
                        "trigger_conditions": "[è¯·å¡«å†™è§¦å‘æ¡ä»¶]",
                        "execution_frequency": "[è¯·å¡«å†™æ‰§è¡Œé¢‘ç‡]",
                        "condition_monitoring": "[è¯·å¡«å†™æ¡ä»¶ç›‘æ§æ–¹æ³•]",
                        "trigger_logic": "[è¯·å¡«å†™è§¦å‘åˆ¤æ–­é€»è¾‘]",
                        "automation_execution": "[è¯·å¡«å†™è‡ªåŠ¨åŒ–æ‰§è¡Œæ­¥éª¤]",
                        "implementation_plan": "[è¯·å¡«å†™å®ç°æ–¹æ¡ˆ]"
                    }
                }
            }
        }
    
    def _select_and_fill_template(self, user_input: str, task_type: str, is_chinese: bool) -> str:
        """Select appropriate template and guide AI to fill in the content."""
        lang = "chinese" if is_chinese else "english"
        template_data = self.task_templates.get(task_type, {}).get(lang, {})
        
        if not template_data:
            # Fallback to generic template
            return self._generate_generic_template(user_input, is_chinese)
        
        # Create a prompt that guides AI to fill the template with strict adherence to original text
        if is_chinese:
            fill_prompt = f"""
ä½ æ˜¯ä¸€ä¸ªOfficeè‡ªåŠ¨åŒ–ä¸“å®¶ã€‚

ğŸ“‹ åŸå§‹ç”¨æˆ·è¯·æ±‚ï¼ˆè¿™æ˜¯ç»å¯¹å‡†ç¡®çš„ä¾æ®ï¼‰ï¼š
"{user_input}"

ğŸ“‹ é¢„è®¾æ¨¡æ¿ç»“æ„ï¼š
{template_data['title']}

{template_data['structure']}

ğŸš¨ é‡è¦æŒ‡ç¤ºï¼š
1. åŸå§‹ç”¨æˆ·è¯·æ±‚æ˜¯å”¯ä¸€æƒå¨ä¾æ®ï¼Œæ‰€æœ‰å†…å®¹å¿…é¡»ä¸¥æ ¼åŸºäºåŸæ–‡
2. å¦‚æœæ¨¡æ¿å†…å®¹ä¸åŸæ–‡å‘ç”Ÿä»»ä½•å†²çªï¼Œå¿…é¡»ä»¥åŸæ–‡ä¸ºå‡†
3. å¡«å†™æ¨¡æ¿æ—¶ï¼Œç›´æ¥ä½¿ç”¨åŸæ–‡ä¸­çš„ç¡®åˆ‡ç”¨è¯å’Œè¡¨è¿°
4. ä¿æŒåŸæ–‡ä¸­çš„æ‰€æœ‰æŠ€æœ¯æœ¯è¯­ã€å­—æ®µåã€è¡¨åç­‰ä¸å˜
5. ä¸è¦æ·»åŠ åŸæ–‡ä¸­æ²¡æœ‰çš„ä¿¡æ¯ï¼Œä¸è¦ä¿®æ”¹åŸæ–‡çš„è¡¨è¾¾æ–¹å¼

âš™ï¸ å¡«å†™è¦æ±‚ï¼š
- å°†æ¨¡æ¿ä¸­çš„å ä½ç¬¦ {{å˜é‡}} æ›¿æ¢ä¸ºåŸºäºåŸæ–‡çš„å…·ä½“å†…å®¹
- å¦‚æœåŸæ–‡ä¿¡æ¯ä¸è¶³ä»¥å¡«å†™æŸä¸ªå ä½ç¬¦ï¼Œæ ‡æ³¨"[åŸæ–‡æœªæ˜ç¡®æŒ‡å®š]"
- ä¿æŒæ¨¡æ¿çš„æ•´ä½“ç»“æ„å’Œæ ¼å¼
- ç¡®ä¿ä¸åŸæ–‡å®Œå…¨ä¸€è‡´

è¯·ä¸¥æ ¼æŒ‰ç…§åŸæ–‡å†…å®¹å¡«å†™æ¨¡æ¿ï¼š
"""
        else:
            fill_prompt = f"""
You are an Office automation expert.

ğŸ“‹ Original User Request (This is the absolute authoritative source):
"{user_input}"

ğŸ“‹ Predefined Template Structure:
{template_data['title']}

{template_data['structure']}

ğŸš¨ Critical Instructions:
1. The original user request is the only authoritative source - all content must strictly follow the original text
2. If there's any conflict between template content and original text, the original text takes precedence
3. When filling the template, use exact wording and expressions from the original text
4. Keep all technical terms, field names, table names, etc. unchanged from the original
5. Do not add information not present in the original text, do not modify the original expressions

âš™ï¸ Filling Requirements:
- Replace template placeholders {{variables}} with specific content based on the original text
- If original text lacks information for a placeholder, mark as "[Not specified in original]"
- Maintain the overall template structure and format
- Ensure complete consistency with the original text

Please fill the template strictly according to the original text content:
"""
        
        return fill_prompt
    
    def _generate_generic_template(self, user_input: str, is_chinese: bool) -> str:
        """Generate a generic template when no specific template matches."""
        if is_chinese:
            return f"""
ğŸ“‹ åŸå§‹ç”¨æˆ·è¯·æ±‚ï¼ˆç»å¯¹æƒå¨ä¾æ®ï¼‰ï¼š
"{user_input}"

åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel

ğŸ“‹ ä»»åŠ¡æ‰§è¡Œè®¡åˆ’ï¼š

ğŸš¨ é‡è¦ï¼šä¸¥æ ¼æŒ‰ç…§åŸæ–‡å†…å®¹å¡«å†™ï¼Œä¸å¾—åç¦»åŸæ–‡è¡¨è¿°

ğŸ¯ ç›®æ ‡åˆ†æï¼ˆåŸºäºåŸæ–‡ï¼‰ï¼š
- å…·ä½“éœ€æ±‚ï¼š[ç›´æ¥å¼•ç”¨åŸæ–‡ä¸­çš„éœ€æ±‚æè¿°ï¼Œä¿æŒåŸæ–‡ç”¨è¯]
- æœŸæœ›ç»“æœï¼š[åŸºäºåŸæ–‡æ¨æ–­çš„é¢„æœŸç»“æœï¼Œä½¿ç”¨åŸæ–‡æœ¯è¯­]

âš™ï¸ æ‰§è¡Œæ­¥éª¤ï¼ˆæŒ‰åŸæ–‡é€»è¾‘ï¼‰ï¼š
1. å‡†å¤‡é˜¶æ®µ
   - [åŸºäºåŸæ–‡ç¡®å®šçš„å‡†å¤‡å·¥ä½œï¼Œä¿æŒåŸæ–‡ä¸­çš„å¯¹è±¡åç§°]
   
2. æ‰§è¡Œé˜¶æ®µ  
   - [ä¸¥æ ¼æŒ‰ç…§åŸæ–‡æè¿°çš„æ“ä½œæ­¥éª¤ï¼Œä½¿ç”¨åŸæ–‡çš„ç¡®åˆ‡è¡¨è¿°]
   
3. éªŒè¯é˜¶æ®µ
   - [åŸºäºåŸæ–‡è¦æ±‚çš„éªŒè¯æ–¹æ³•]

ğŸ’¡ å®ç°å»ºè®®ï¼ˆå¿ äºåŸæ–‡ï¼‰ï¼š
[æä¾›ä¸åŸæ–‡å®Œå…¨ä¸€è‡´çš„å®ç°æ–¹æ¡ˆï¼Œä¿æŒæ‰€æœ‰æŠ€æœ¯æœ¯è¯­ä¸å˜]

âœ… æˆåŠŸæ ‡å‡†ï¼ˆåŸæ–‡æ ‡å‡†ï¼‰ï¼š
- [æ ¹æ®åŸæ–‡å®šä¹‰çš„å®Œæˆæ ‡å‡†ï¼Œä¸æ·»åŠ é¢å¤–è¦æ±‚]

âš ï¸ å¡«å†™åŸåˆ™ï¼š
1. æ‰€æœ‰å†…å®¹å¿…é¡»åŸºäºåŸæ–‡
2. ä¿æŒåŸæ–‡ä¸­çš„ç¡®åˆ‡ç”¨è¯
3. ä¸æ·»åŠ åŸæ–‡æœªæåŠçš„ä¿¡æ¯
4. å¦‚ä¿¡æ¯ä¸è¶³ï¼Œæ ‡æ³¨"[åŸæ–‡æœªæ˜ç¡®]"
"""
        else:
            return f"""
ğŸ“‹ Original User Request (Absolute Authority):
"{user_input}"

App Selection: 0=Word, 1=Excel

ğŸ“‹ Task Execution Plan:

ğŸš¨ Important: Fill strictly according to original text, no deviation from original expressions

ğŸ¯ Objective Analysis (Based on Original):
- Specific Requirements: [Quote requirement descriptions directly from original text, maintain original wording]
- Expected Results: [Expected outcomes inferred from original text, using original terminology]

âš™ï¸ Execution Steps (Following Original Logic):
1. Preparation Phase
   - [Preparation work determined from original text, maintain object names from original]
   
2. Execution Phase
   - [Strictly follow operation steps described in original text, use exact original expressions]
   
3. Validation Phase
   - [Validation methods based on original requirements]

ğŸ’¡ Implementation Suggestions (Faithful to Original):
[Provide implementation plans completely consistent with original text, maintain all technical terms unchanged]

âœ… Success Criteria (Original Standards):
- [Completion standards defined according to original text, no additional requirements]

âš ï¸ Filling Principles:
1. All content must be based on original text
2. Maintain exact wording from original
3. Do not add information not mentioned in original
4. If information insufficient, mark "[Not specified in original]"
"""
    
    def _classify_task_type(self, user_input: str) -> str:
        """Classify user input into predefined task types for template selection."""
        user_lower = user_input.lower()
        
        # Data extraction patterns
        extraction_patterns = [
            "æå–", "æŠ½å–", "è·å–", "åˆ†ç¦»", "extract", "parse", "get", "retrieve", 
            "split", "separate", "pull out", "æ‹†åˆ†", "åˆ†è§£"
        ]
        
        # Content generation patterns  
        content_patterns = [
            "å†™", "åˆ›å»º", "ç”Ÿæˆ", "åˆ¶ä½œ", "ç¼–å†™", "èµ·è‰", "write", "create", "generate", 
            "draft", "compose", "produce", "æ–‡æ¡£", "æŠ¥å‘Š", "ä¿¡ä»¶", "document", "report", "letter"
        ]
        
        # Data processing patterns
        processing_patterns = [
            "å¤„ç†", "è½¬æ¢", "æ ¼å¼åŒ–", "æ¸…æ´—", "æ ‡å‡†åŒ–", "process", "convert", "format", 
            "clean", "normalize", "transform", "è®¡ç®—", "ç»Ÿè®¡", "åˆ†æ", "calculate", "analyze"
        ]
        
        # Automation patterns
        automation_patterns = [
            "è‡ªåŠ¨åŒ–", "æ‰¹é‡", "é‡å¤", "å®šæ—¶", "automate", "batch", "bulk", "repeat", 
            "schedule", "macro", "å®", "è„šæœ¬", "script"
        ]
        
        # Score each category
        scores = {
            "data_extraction": sum(1 for pattern in extraction_patterns if pattern in user_lower),
            "content_generation": sum(1 for pattern in content_patterns if pattern in user_lower), 
            "data_processing": sum(1 for pattern in processing_patterns if pattern in user_lower),
            "automation_task": sum(1 for pattern in automation_patterns if pattern in user_lower)
        }
        
        # Return highest scoring category, or None if no clear match
        max_score = max(scores.values())
        if max_score > 0:
            return max(scores, key=scores.get)
        
        return "generic"  # Fallback to generic template
    
    async def _handle_app_selection(self, app_selection: str) -> str:
        """Handle app selection (0/1) with template processing."""
        app_name = "Word" if app_selection == '0' else "Excel"
        is_chinese = any('\u4e00' <= char <= '\u9fff' for char in '\u4e00')  # Default check
        
        # Extract previous task from conversation history
        previous_task = self._extract_previous_task_context()
        if not previous_task:
            # No previous context, fall back to generic response
            if is_chinese:
                return f"âœ… å·²é€‰æ‹©{app_name}\n\nè¯·è¯¦ç»†æè¿°ä½ è¦å®Œæˆçš„å…·ä½“ä»»åŠ¡ï¼š\n- æ•°æ®æ“ä½œè¯·æè¿°å…·ä½“æ­¥éª¤\n- å†…å®¹åˆ›ä½œè¯·è¯´æ˜ä¸»é¢˜å’Œè¦æ±‚\n- æ ¼å¼è°ƒæ•´è¯·æ˜ç¡®ç›®æ ‡æ ·å¼"
            return f"âœ… Selected {app_name}\n\nPlease describe your specific task in detail:\n- For data operations: describe specific steps\n- For content creation: specify topic and requirements\n- For formatting: clarify target style"
        
        # Determine if previous task was in Chinese
        is_chinese = any('\u4e00' <= char <= '\u9fff' for char in previous_task)
        
        # Create AI prompt to generate complete solution directly
        ai_prompt = self._create_solution_prompt(previous_task, app_name, is_chinese)
        
        # Try to have AI generate the complete solution
        try:
            if self.ai_service.is_available():
                ai_solution = await self.ai_service.process_message(ai_prompt)
                if ai_solution and len(ai_solution.strip()) > 50:  # Ensure we got a substantial response
                    return f"âœ… å·²é€‰æ‹©{app_name}\n\n{ai_solution}" if is_chinese else f"âœ… Selected {app_name}\n\n{ai_solution}"
        except Exception as e:
            print(f"AI solution generation error: {e}")
        
        # Fallback to template-based approach if AI fails
        task_type = self._classify_task_type(previous_task)
        if task_type in self.task_templates:
            template_response = self._select_and_fill_template_with_app(previous_task, task_type, app_selection, is_chinese)
            return f"âœ… å·²é€‰æ‹©{app_name}\n\n{template_response}" if is_chinese else f"âœ… Selected {app_name}\n\n{template_response}"
        else:
            generic_template = self._generate_generic_template_with_app(previous_task, app_selection, is_chinese)
            return f"âœ… å·²é€‰æ‹©{app_name}\n\n{generic_template}" if is_chinese else f"âœ… Selected {app_name}\n\n{generic_template}"
    
    def _create_solution_prompt(self, user_task: str, app_name: str, is_chinese: bool) -> str:
        """Create a focused AI prompt to generate complete solution directly."""
        if is_chinese:
            return f"""ç”¨æˆ·ä»»åŠ¡ï¼š{user_task}
ç›®æ ‡åº”ç”¨ï¼š{app_name}

è¯·ç›´æ¥ç”Ÿæˆå®Œæ•´çš„å¯æ‰§è¡Œè§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š
1. å…·ä½“çš„æ“ä½œæ­¥éª¤ï¼ˆè¯¦ç»†è¯´æ˜æ¯ä¸€æ­¥å¦‚ä½•åœ¨{app_name}ä¸­æ‰§è¡Œï¼‰
2. éœ€è¦çš„å…¬å¼æˆ–ä»£ç ï¼ˆå¦‚æœæ¶‰åŠæ•°æ®å¤„ç†ï¼Œæä¾›å®Œæ•´çš„Excelå…¬å¼æˆ–VBAä»£ç ï¼‰
3. å®é™…ç¤ºä¾‹ï¼ˆåŸºäºç”¨æˆ·ä»»åŠ¡çš„å…·ä½“ç¤ºä¾‹ï¼‰
4. æ³¨æ„äº‹é¡¹å’ŒéªŒè¯æ–¹æ³•

è¦æ±‚ï¼š
- ç›´æ¥æä¾›å¯æ“ä½œçš„è§£å†³æ–¹æ¡ˆï¼Œä¸è¦åªæ˜¯æ¡†æ¶æˆ–æ¨¡æ¿
- ä¿æŒåŸæ–‡ä¸­çš„æ‰€æœ‰å…³é”®ä¿¡æ¯ï¼ˆè¡¨åã€å­—æ®µåã€æœ¯è¯­ç­‰ï¼‰
- æä¾›å…·ä½“çš„å®ç°ç»†èŠ‚ï¼Œä¸è¦æŠ½è±¡æè¿°
- å¦‚æœæ˜¯æ•°æ®å¤„ç†ä»»åŠ¡ï¼Œå¿…é¡»åŒ…å«å…·ä½“çš„Excelå…¬å¼

è¯·ç°åœ¨å°±ç”Ÿæˆå®Œæ•´çš„è§£å†³æ–¹æ¡ˆï¼š"""
        else:
            return f"""User Task: {user_task}
Target Application: {app_name}

Please generate a complete executable solution directly, including:
1. Specific operational steps (detailed instructions for each step in {app_name})
2. Required formulas or code (if data processing is involved, provide complete Excel formulas or VBA code)
3. Practical examples (specific examples based on the user's task)
4. Important notes and validation methods

Requirements:
- Provide directly actionable solutions, not just frameworks or templates
- Preserve all key information from the original text (table names, field names, terminology, etc.)
- Include specific implementation details, not abstract descriptions
- If it's a data processing task, must include specific Excel formulas

Please generate the complete solution now:"""
    
    def _extract_previous_task_context(self) -> str:
        """Extract the original task from conversation history when user selects app."""
        if len(self.conversation_history) < 2:
            return ""
        
        # Look for the most recent substantive user request (not app selection)
        for msg in reversed(self.conversation_history):
            if msg['role'] == 'user' and msg['content'].strip() not in ['0', '1', '/c', '/clear', '/mb', '/ms', '/model-big', '/model-small']:
                return msg['content']
        
        return ""
    
    def _select_and_fill_template_with_app(self, user_input: str, task_type: str, app_selection: str, is_chinese: bool) -> str:
        """Create template with app selection already filled in."""
        lang = "chinese" if is_chinese else "english"
        template_data = self.task_templates.get(task_type, {}).get(lang, {})
        
        if not template_data:
            return self._generate_generic_template_with_app(user_input, app_selection, is_chinese)
        
        # Fill the app_selection in the template structure
        filled_structure = template_data['structure'].replace('{app_selection}', f"{app_selection}={'Word' if app_selection == '0' else 'Excel'}")
        
        if is_chinese:
            return f"""åŸºäºæ‚¨çš„åŸå§‹éœ€æ±‚ï¼Œå·²ä¸ºæ‚¨å‡†å¤‡æ‰§è¡Œæ¨¡æ¿ï¼š

ğŸ“‹ åŸå§‹éœ€æ±‚ï¼ˆæƒå¨ä¾æ®ï¼‰ï¼š"{user_input}"

ğŸ“‹ {template_data['title']}

{filled_structure}

ğŸš¨ æ™ºèƒ½å¡«å†™æŒ‡ç¤ºï¼š
- åŸºäºåŸå§‹éœ€æ±‚ï¼Œè¿ç”¨AIèƒ½åŠ›æ™ºèƒ½æ¨æ–­å’Œè¡¥å……ç»†èŠ‚
- ä¿æŒåŸæ–‡ä¸­çš„ç¡®åˆ‡ç”¨è¯å’ŒæŠ€æœ¯æœ¯è¯­ä¸å˜
- å¯¹äºåŸæ–‡æœªæ˜ç¡®çš„ä¿¡æ¯ï¼Œæä¾›åˆç†çš„ä¸šåŠ¡é€»è¾‘æ¨æ–­
- ç”Ÿæˆå¯ç›´æ¥æ‰§è¡Œçš„å®Œæ•´æ–¹æ¡ˆï¼ŒåŒ…æ‹¬å…·ä½“çš„å…¬å¼å’Œæ­¥éª¤

ğŸ’¡ AIå¤„ç†æ–¹å¼ï¼š
- ç†è§£ä¸šåŠ¡åœºæ™¯ï¼šå®¢æˆ·ç®¡ç†ç³»ç»Ÿçš„è´¢åŠ¡æ±‡æ€»éœ€æ±‚
- æ¨æ–­æ•°æ®ç»“æ„ï¼šåŸºäºå¸¸è§çš„å®¢æˆ·ã€åˆåŒã€æ”¶æ¬¾è¡¨ç»“æ„
- ç”Ÿæˆå®ç”¨æ–¹æ¡ˆï¼šæä¾›Excelå…¬å¼æˆ–VBAä»£ç å®ç°
- åŒ…å«å®Œæ•´è¯´æ˜ï¼šä»å‡†å¤‡åˆ°éªŒè¯çš„å…¨è¿‡ç¨‹

è¯·è¿ç”¨AIçš„è‡ªç„¶è¯­è¨€ç†è§£èƒ½åŠ›ï¼Œç›´æ¥ç”Ÿæˆå®Œæ•´å¯æ‰§è¡Œçš„è§£å†³æ–¹æ¡ˆï¼š"""
        else:
            return f"""Based on your original request, execution template prepared:

ğŸ“‹ Original Request (Authoritative Source): "{user_input}"

ğŸ“‹ {template_data['title']}

{filled_structure}

ğŸš¨ Intelligent Processing Instructions:
- Based on original request, use AI capabilities to intelligently infer and supplement details
- Maintain exact wording and technical terms from original unchanged
- For information not explicitly stated, provide reasonable business logic inferences
- Generate directly executable complete solution including specific formulas and steps

ğŸ’¡ AI Processing Approach:
- Understand business scenario: Customer management system financial summary requirements
- Infer data structures: Based on common customer, contract, payment table structures
- Generate practical solution: Provide Excel formulas or VBA code implementation
- Include complete instructions: Full process from preparation to validation

Please use AI's natural language understanding capabilities to directly generate a complete executable solution:"""
    
    def _generate_generic_template_with_app(self, user_input: str, app_selection: str, is_chinese: bool) -> str:
        """Generate generic template with app already selected."""
        app_name = "Word" if app_selection == "0" else "Excel"
        
        if is_chinese:
            return f"""åŸºäºæ‚¨çš„åŸå§‹éœ€æ±‚ï¼š"{user_input}"

ğŸ“‹ ä»»åŠ¡æ‰§è¡Œè®¡åˆ’ï¼ˆ{app_name}ï¼‰

ğŸ¯ ç›®æ ‡åˆ†æï¼ˆåŸºäºåŸæ–‡ï¼‰ï¼š
- å…·ä½“éœ€æ±‚ï¼š[ç›´æ¥å¼•ç”¨åŸæ–‡éœ€æ±‚ï¼Œä¿æŒåŸæ–‡ç”¨è¯]
- æœŸæœ›ç»“æœï¼š[åŸºäºåŸæ–‡çš„é¢„æœŸç»“æœ]

âš™ï¸ æ‰§è¡Œæ­¥éª¤ï¼š
1. å‡†å¤‡é˜¶æ®µ
   - [åŸºäºåŸæ–‡çš„å‡†å¤‡å·¥ä½œ]
   
2. æ‰§è¡Œé˜¶æ®µ
   - [ä¸¥æ ¼æŒ‰åŸæ–‡çš„æ“ä½œæ­¥éª¤]
   
3. éªŒè¯é˜¶æ®µ
   - [åŸæ–‡è¦æ±‚çš„éªŒè¯æ–¹æ³•]

ğŸ’¡ AIæ™ºèƒ½å®ç°æ–¹æ¡ˆï¼š
è¯·åŸºäºä¸šåŠ¡å¸¸è¯†å’ŒExcelæœ€ä½³å®è·µï¼Œç”ŸæˆåŒ…å«ä»¥ä¸‹å†…å®¹çš„å®Œæ•´æ–¹æ¡ˆï¼š
- å…·ä½“çš„Excelå…¬å¼ï¼ˆå¦‚SUMIFã€VLOOKUPç­‰ï¼‰
- è¯¦ç»†çš„æ“ä½œæ­¥éª¤è¯´æ˜
- æ•°æ®éªŒè¯å’Œæµ‹è¯•æ–¹æ³•
- å¯èƒ½é‡åˆ°çš„é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

ğŸ¯ æœŸæœ›è¾“å‡ºï¼šç›´æ¥å¯ç”¨çš„Excelè§£å†³æ–¹æ¡ˆï¼Œæ— éœ€ç”¨æˆ·å†æ¬¡æä¾›æŠ€æœ¯ç»†èŠ‚"""
        else:
            return f"""Based on your original request: "{user_input}"

ğŸ“‹ Task Execution Plan ({app_name})

ğŸ¯ Objective Analysis (Based on Original):
- Specific Requirements: [Quote directly from original, maintain original wording]
- Expected Results: [Expected outcomes from original]

âš™ï¸ Execution Steps:
1. Preparation Phase
   - [Preparation work based on original]
   
2. Execution Phase
   - [Operation steps strictly from original]
   
3. Validation Phase
   - [Validation methods required by original]

ğŸ’¡ AI Intelligent Implementation Plan:
Please generate a complete solution based on business common sense and Excel best practices, including:
- Specific Excel formulas (such as SUMIF, VLOOKUP, etc.)
- Detailed operational step-by-step instructions  
- Data validation and testing methods
- Potential issues and solutions

ğŸ¯ Expected Output: Directly usable Excel solution without requiring users to provide additional technical details"""
    
    async def _pass_through_to_ai(self, user_input: str) -> str:
        """Pass user input directly to AI with minimal optimization, trusting big model capabilities."""
        # Create minimal context
        context = ""
        if len(self.conversation_history) > 1:
            context = "\nPrevious conversation:\n"
            # Only use last 3 messages to keep it minimal
            for msg in self.conversation_history[-3:]:
                context += f"{msg['role']}: {msg['content']}\n"
        
        # Minimal prompt for big model
        minimal_prompt = f"""You are an expert Office automation assistant.

User Request: {user_input}
{context}
App Selection: Use "0=Word, 1=Excel" format

Provide a comprehensive, practical solution. Use your full capabilities to understand the request and deliver the best approach."""
        
        # Try AI service
        if self.ai_service.is_available():
            try:
                result = await self.ai_service.process_message(minimal_prompt)
                if result:
                    self.add_to_history("assistant", result)
                    return result
            except Exception as ai_error:
                print(f"âš ï¸  AI service error in trust mode: {ai_error}")
        
        # Fallback with trust mode acknowledgment
        is_chinese = any('\u4e00' <= char <= '\u9fff' for char in user_input)
        if is_chinese:
            return f"Task: '{user_input}'\n\nğŸ¤– AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œä½†æ‚¨çš„è¯·æ±‚å·²è®°å½•ã€‚\nåº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\n\nè¯·é€‰æ‹©åº”ç”¨ç¨‹åºç»§ç»­æ“ä½œã€‚"
        else:
            return f"Task: '{user_input}'\n\nğŸ¤– AI service temporarily unavailable, but your request is recorded.\nApp: 0=Word, 1=Excel\n\nPlease select the application to continue."
    
    def _validate_information_preservation(self, original_input: str, optimized_response: str) -> bool:
        """Validate that optimized response preserves core information from original input."""
        original_lower = original_input.lower()
        response_lower = optimized_response.lower()
        
        # Extract key elements from original input with enhanced detection
        key_elements = []
        
        # Check for specific tools/applications mentioned
        apps = ["word", "excel", "powerpoint", "office", "æ–‡æ¡£", "è¡¨æ ¼", "æ¼”ç¤º"]
        mentioned_apps = [app for app in apps if app in original_lower]
        key_elements.extend(mentioned_apps)
        
        # Check for action verbs (what user wants to do)
        actions = ["create", "generate", "write", "format", "calculate", "extract", "split", "convert", 
                  "automate", "batch", "process", "analyze", "add", "å¢åŠ ", "åˆ›å»º", "ç”Ÿæˆ", "å†™", "æ ¼å¼", "è®¡ç®—", "æå–", 
                  "æ‹†åˆ†", "è½¬æ¢", "è‡ªåŠ¨åŒ–", "æ‰¹å¤„ç†", "å¤„ç†", "åˆ†æ", "å¡«å…¥", "å¡«å……"]
        mentioned_actions = [action for action in actions if action in original_lower]
        key_elements.extend(mentioned_actions)
        
        # Check for specific data types or objects
        objects = ["table", "chart", "document", "file", "data", "text", "number", "date", "image", 
                  "è¡¨æ ¼", "å›¾è¡¨", "æ–‡æ¡£", "æ–‡ä»¶", "æ•°æ®", "æ–‡æœ¬", "æ•°å­—", "æ—¥æœŸ", "å›¾ç‰‡", "å­—æ®µ", "åˆ—", "è¡Œ"]
        mentioned_objects = [obj for obj in objects if obj in original_lower]
        key_elements.extend(mentioned_objects)
        
        # Enhanced detection for business-specific terms
        business_terms = ["å®¢æˆ·", "customer", "çœ", "å¸‚", "province", "city", "åœ°å€", "address", "è¯¦ç»†", "detailed"]
        mentioned_business = [term for term in business_terms if term in original_lower]
        key_elements.extend(mentioned_business)
        
        # Check for field names and technical specifications (quoted strings)
        import re
        quoted_terms = re.findall(r'[""\'](.*?)[""\'"]', original_input)
        key_elements.extend([term.lower() for term in quoted_terms])
        
        # Check for specific database/table terminology
        db_terms = ["è¡¨", "table", "å­—æ®µ", "field", "åˆ—", "column", "è¡Œ", "row", "æ•°æ®åº“", "database"]
        mentioned_db = [term for term in db_terms if term in original_lower]
        key_elements.extend(mentioned_db)
        
        # Check preservation rate with different thresholds for different model types
        if not key_elements:
            return True  # No specific elements to validate
            
        preserved_count = sum(1 for element in key_elements if element in response_lower)
        preservation_rate = preserved_count / len(key_elements)
        
        # Big models require much higher preservation rate (95%), small models require 70%
        if self.target_model_type == "big":
            required_rate = 0.95  # 95% preservation for big models
        else:
            required_rate = 0.70  # 70% preservation for small models
        
        return preservation_rate >= required_rate
    
    def _validate_template_fidelity(self, original_input: str, template_response: str) -> bool:
        """Validate that template response maintains fidelity to original user input."""
        original_lower = original_input.lower()
        response_lower = template_response.lower()
        
        # Extract quoted strings and technical terms from original
        import re
        quoted_terms = re.findall(r'[""\'](.*?)[""\'"]', original_input)
        
        # Check if all quoted terms are preserved
        for term in quoted_terms:
            if term.lower() not in response_lower:
                return False
        
        # Check for critical business terms preservation
        critical_terms = []
        
        # Extract table/object names (Chinese patterns)
        table_patterns = re.findall(r'(\w*è¡¨\w*)', original_input)
        critical_terms.extend(table_patterns)
        
        # Extract field/column names (Chinese patterns)
        field_patterns = re.findall(r'(\w*å­—æ®µ\w*)', original_input)
        critical_terms.extend(field_patterns)
        
        # Check preservation of critical terms
        for term in critical_terms:
            if term and term.lower() not in response_lower:
                return False
        
        # For template responses, require higher fidelity (90%)
        return self._validate_information_preservation(original_input, template_response)
    
    def _add_original_text_reminder(self, original_input: str, ai_response: str, is_chinese: bool) -> str:
        """Add original text reminder when template response may have deviated."""
        if is_chinese:
            reminder = f"""
{ai_response}

ğŸš¨ é‡è¦æé†’ï¼šè¯·ä¸¥æ ¼å‚è€ƒåŸå§‹éœ€æ±‚
åŸå§‹éœ€æ±‚ï¼š"{original_input}"

å¦‚æœä¸Šè¿°å›å¤ä¸æ‚¨çš„åŸå§‹éœ€æ±‚æœ‰ä»»ä½•ä¸ç¬¦ï¼Œè¯·ä»¥æ‚¨çš„åŸå§‹éœ€æ±‚ä¸ºå‡†ã€‚æ‰€æœ‰è¡¨åã€å­—æ®µåã€æ“ä½œæ­¥éª¤éƒ½åº”è¯¥ä¸¥æ ¼æŒ‰ç…§æ‚¨æä¾›çš„åŸå§‹æè¿°æ‰§è¡Œã€‚
"""
        else:
            reminder = f"""
{ai_response}

ğŸš¨ Important Reminder: Please strictly refer to original requirements
Original Request: "{original_input}"

If the above response has any inconsistency with your original requirements, please follow your original requirements. All table names, field names, and operation steps should strictly follow your original description.
"""
        
        return reminder
    
    def get_capability_recommendation(self, user_input: str) -> CapabilityRecommendation:
        """Get AI vs VBA capability recommendation for the task."""
        return self.analyzer.analyze_task(user_input)
    
    async def optimize_prompt(self, user_input: str) -> str:
        """Main optimization method that returns the best response."""
        try:
            # Add user input to history
            self.add_to_history("user", user_input)
            
            # For big models in trust mode, check if we should pass through or ask clarifying questions
            if self.target_model_type == "big" and self.trust_mode:
                trust_decision = self._evaluate_trust_mode(user_input)
                if trust_decision["action"] == "pass_through":
                    # Trust the big model - pass through with minimal context
                    return await self._pass_through_to_ai(user_input)
                elif trust_decision["action"] == "clarify":
                    # Ask intelligent clarifying questions
                    return trust_decision["response"]
            
            # Handle app selection responses (0/1) FIRST before any other processing
            if user_input.strip() in ['0', '1']:
                return await self._handle_app_selection(user_input.strip())
            
            # Analyze task capability to determine if it's a fuzzy AI task
            capability = self.get_capability_recommendation(user_input)
            
            # Determine task type and use appropriate template
            task_type = self._classify_task_type(user_input)
            is_chinese = any('\u4e00' <= char <= '\u9fff' for char in user_input)
            
            # Use template-driven approach for clear task types
            if task_type in self.task_templates:
                template_prompt = self._select_and_fill_template(user_input, task_type, is_chinese)
                # Pass template to AI for content filling
                if self.ai_service.is_available():
                    try:
                        result = await self.ai_service.process_message(template_prompt)
                        if result:
                            # Enhanced validation specifically for template-based responses
                            if self._validate_template_fidelity(user_input, result):
                                self.add_to_history("assistant", result)
                                return result
                            else:
                                # Original text fidelity failed, enhance with warning
                                print(f"âš ï¸  Template response may have deviated from original text")
                                enhanced_result = self._add_original_text_reminder(user_input, result, is_chinese)
                                self.add_to_history("assistant", enhanced_result)
                                return enhanced_result
                    except Exception as e:
                        print(f"Template processing error: {e}")
            
            # Create context-aware prompt with enhanced context preservation
            context = ""
            if len(self.conversation_history) > 1:
                context = "\\nPrevious conversation:\\n"
                # Use last 10 messages for better context preservation
                recent_messages = self.conversation_history[-10:]
                
                # If conversation is very long, include a summary of earlier context
                if len(self.conversation_history) > 10:
                    earlier_messages = self.conversation_history[:-10]
                    # Extract key information from earlier messages
                    key_info = self._extract_key_information(earlier_messages)
                    if key_info:
                        context += f"Earlier context summary: {key_info}\\n\\n"
                
                # Add recent messages with full detail
                for msg in recent_messages:
                    context += f"{msg['role']}: {msg['content']}\\n"
            
            target_model_info = self.model_types[self.target_model_type]
            
            # Special handling for fuzzy AI tasks using Structured Data Analysis Framework
            if capability.recommendation == "FUZZY_AI":
                # Enhanced prompts for big models with maximum detail preservation
                if self.target_model_type == "big":
                    full_prompt = f"""
You are an advanced OfficeAI assistant with sophisticated analytical capabilities for complex data processing tasks.

ğŸ§  STRUCTURED DATA ANALYSIS FRAMEWORK (SDAF) MODE ACTIVATED - BIG MODEL ENHANCED
Task Type: {capability.reason}
Target Model: {target_model_info['name']}
Information Preservation: {target_model_info['information_loss_tolerance']} loss tolerance
Context Preservation: {target_model_info['context_preservation']} detail level

âš ï¸ CRITICAL INFORMATION PRESERVATION REQUIREMENTS:
- PRESERVE ALL original terminology, field names, table names, and technical specifications
- MAINTAIN ALL contextual details from user request
- RETAIN ALL conditional logic and processing requirements
- PRESERVE ALL specific data examples and formats mentioned
- KEEP ALL language-specific terms and cultural context
- MAINTAIN ALL business logic and workflow requirements

ğŸ“‹ COMPREHENSIVE SDAF FRAMEWORK FOR BIG MODELS:

ğŸ” PHASE 1: COMPREHENSIVE DATA DISCOVERY & ASSESSMENT
STEP 1: Detailed Data Structure Analysis
- Examine ALL data formats mentioned: Excel tables, CSV files, text documents, mixed sources
- Identify ALL data types: text fields, numeric columns, date formats, mixed content
- Detect ALL patterns: delimiters, separators, formatting conventions, encoding
- Note ALL inconsistencies: missing values, special characters, formatting variations, edge cases
- Map ALL relationships: primary keys, foreign keys, dependent fields, calculated columns

STEP 2: Multi-Dimensional Complexity Assessment
- SIMPLE: Consistent structure, clean data, standard formats â†’ Direct automation sufficient
- MEDIUM: Some inconsistencies, multiple formats, minor variations â†’ Guided processing needed
- COMPLEX: Mixed structures, messy text, significant variations â†’ AI reasoning required
- FUZZY: Requires interpretation, context understanding, cultural knowledge â†’ Full AI capabilities essential

ğŸ¯ PHASE 2: COMPREHENSIVE PROCESSING STRATEGY DESIGN
STEP 3: Multi-Modal Processing Approach Selection
- Direct automation (VBA/formulas/built-in functions) for consistent, structured data
- AI-powered reasoning for inconsistent, contextual, or culturally-dependent data
- Hybrid approach combining automation efficiency with AI intelligence for mixed scenarios
- Custom algorithm development for unique or specialized processing requirements

STEP 4: Advanced Text Processing Strategy Design
COMPREHENSIVE TEXT STRUCTURE HANDLING:
- Structured text â†’ Advanced pattern matching, regex with validation, template-based extraction
- Semi-structured â†’ AI interpretation with rule validation, confidence scoring, exception handling
- Unstructured â†’ Full natural language processing, semantic analysis, contextual understanding
- Mixed formats â†’ Dynamic format detection, adaptive processing pipeline, progressive refinement

âš™ï¸ PHASE 3: DETAILED IMPLEMENTATION GUIDANCE
STEP 5: Systematic Processing Methodology
A. COMPREHENSIVE READ & PARSE:
   1. Sample diverse data sets to understand complete pattern spectrum and edge cases
   2. Identify ALL exception scenarios, outliers, and boundary conditions
   3. Plan comprehensive error handling, logging, and recovery strategies
   4. Design validation checkpoints and quality assurance measures

B. INTELLIGENT PROCESS & TRANSFORM:
   1. Apply consistent automation rules where data structure permits reliable processing
   2. Use advanced AI reasoning for ambiguous, contextual, or culturally-dependent cases
   3. Implement continuous validation with confidence scoring and uncertainty flagging
   4. Handle exceptions gracefully with fallback strategies and manual review workflows

C. COMPREHENSIVE OUTPUT & VERIFY:
   1. Format results with consistent structure while preserving source data integrity
   2. Perform multi-level data integrity checks: syntax, semantics, business logic
   3. Provide detailed processing summary with statistics, confidence levels, and quality metrics
   4. Generate comprehensive audit trail for accountability and debugging

ğŸ“ PHASE 4: SPECIALIZED TEXT HANDLING EXPERTISE

FOR NAME/CONTACT DATA (Enhanced for Cultural Sensitivity):
- Handle ALL formats: "å§“, å", "å å§“", "ç§°è°“ å å§“, åç¼€", international variations
- Process titles, suffixes, special characters, diacritical marks, cultural naming conventions
- Normalize spacing, capitalization, punctuation while preserving cultural authenticity
- Handle multi-language names, transliterations, and phonetic variations

FOR ADDRESS DATA (Enhanced for Geographic Complexity):
- Parse ALL formats: "çœå¸‚åŒºè¡—é“å·", "Street, City, State ZIP", international formats
- Handle abbreviations: "çœ/Province", "å¸‚/City", "åŒº/District", "è¡—/Street", "å·/Number"
- Extract ALL components: country, province/state, city, district, street, building, unit, postal code
- Manage address hierarchies, administrative divisions, and geographic relationships

FOR MIXED CONTENT (Enhanced for Complex Scenarios):
- Identify ALL content types within single text fields: structured data, free text, codes, references
- Separate structured from unstructured information with precision and context preservation
- Apply appropriate processing methodology to each component while maintaining relationships
- Handle nested structures, embedded formats, and multi-layer encoding

FOR INCONSISTENT DATA (Enhanced AI-Powered Resolution):
- Use advanced contextual clues, semantic analysis, and cultural knowledge to interpret intent
- Apply sophisticated fuzzy matching algorithms with confidence scoring and similarity metrics
- Flag uncertain cases with detailed explanations and suggested manual review priorities
- Provide alternative interpretations and processing options for ambiguous scenarios

ğŸ¯ ENHANCED CRITICAL EXECUTION RULES FOR BIG MODELS:
- LANGUAGE: Respond in SAME LANGUAGE as request with full linguistic and cultural preservation
- METHODOLOGY: Follow SDAF phases systematically with comprehensive documentation
- REASONING: Provide detailed analytical process explanation with decision rationale
- PRESERVATION: Maintain ALL original information with {target_model_info['information_loss_tolerance']} loss tolerance
- ADAPTATION: Utilize full big model capabilities for {target_model_info['max_detail']} detail processing
- VALIDATION: Implement multi-level verification with confidence assessment and quality metrics

App Selection Format: "0=Word, 1=Excel"

ORIGINAL USER REQUEST (PRESERVE ALL DETAILS): {user_input}

{context}

{self._get_domain_specific_guidance(capability.reason, any('\u4e00' <= char <= '\u9fff' for char in user_input))}

RESPOND using full SDAF methodology with MAXIMUM detail preservation IN SAME LANGUAGE:"""
                else:
                    # Standard prompt for small models
                    full_prompt = f"""
You are an OfficeAI assistant with advanced analytical capabilities for complex data processing tasks.

ğŸ§  STRUCTURED DATA ANALYSIS FRAMEWORK (SDAF) MODE ACTIVATED
Task Type: {capability.reason}
Target Model: {target_model_info['name']}

ğŸ“‹ FOLLOW THIS SYSTEMATIC FRAMEWORK:

ğŸ” PHASE 1: DATA DISCOVERY & ASSESSMENT
STEP 1: Data Structure Analysis
- Examine input data format (Excel, CSV, text, mixed)
- Identify data types (text, numbers, dates, mixed)
- Detect patterns, delimiters, and structure inconsistencies
- Note missing values, special characters, edge cases

STEP 2: Complexity Assessment
- SIMPLE: Consistent structure, clean data â†’ Use direct automation
- MEDIUM: Some inconsistencies, multiple formats â†’ Use guided processing
- COMPLEX: Mixed structures, messy text â†’ Use AI reasoning
- FUZZY: Requires interpretation and context â†’ Use full AI capabilities

ğŸ¯ PHASE 2: PROCESSING STRATEGY DESIGN
STEP 3: Choose Processing Approach
- Direct automation (VBA/formulas) for consistent data
- AI reasoning for inconsistent/contextual data
- Hybrid approach for mixed complexity scenarios

STEP 4: Text Processing Strategy
TEXT STRUCTURE HANDLING:
- Structured text â†’ Pattern matching/regex approach
- Semi-structured â†’ AI interpretation + validation rules
- Unstructured â†’ Full natural language processing
- Mixed formats â†’ Adaptive processing per data case

âš™ï¸ PHASE 3: IMPLEMENTATION GUIDANCE
STEP 5: Systematic Processing
A. READ & PARSE:
   1. Sample data to understand patterns and variations
   2. Identify edge cases and exception scenarios
   3. Plan comprehensive error handling strategy

B. PROCESS & TRANSFORM:
   1. Apply consistent rules where data allows
   2. Use AI reasoning for ambiguous/contextual cases
   3. Validate results continuously and handle exceptions

C. OUTPUT & VERIFY:
   1. Format results with consistent structure
   2. Perform data integrity checks
   3. Provide detailed processing summary

ğŸ“ PHASE 4: SPECIALIZED TEXT HANDLING GUIDES

FOR NAME/CONTACT DATA:
- Handle formats: "Last, First" vs "First Last" vs "Title First Last, Suffix"
- Process titles, suffixes, special characters, cultural variations
- Normalize spacing, capitalization, and punctuation

FOR ADDRESS DATA:
- Parse: "123 Main St, City, State ZIP" vs "Street\\nCity State ZIP"
- Handle abbreviations: "St/Street", "Ave/Avenue", "Rd/Road"
- Extract components: street number, name, unit, city, state, postal code

FOR MIXED CONTENT:
- Identify content types within single text fields
- Separate structured from unstructured information
- Apply appropriate processing methodology to each part

FOR INCONSISTENT DATA:
- Use contextual clues to interpret user intent
- Apply fuzzy matching algorithms for similar entries
- Flag uncertain cases for manual review/verification

ğŸ¯ CRITICAL EXECUTION RULES:
- LANGUAGE: Respond in SAME LANGUAGE as request (Chineseâ†’Chinese, Englishâ†’English)
- METHODOLOGY: Follow SDAF phases systematically
- REASONING: Explain your analytical process and decisions
- ADAPTATION: Adjust complexity based on target model: {self.target_model_type} needs {target_model_info['max_detail']} detail
- VALIDATION: Always verify results and provide confidence levels

App Selection Format: "0=Word, 1=Excel"

{context}
Current complex data task: {user_input}

{self._get_domain_specific_guidance(capability.reason, any('\u4e00' <= char <= '\u9fff' for char in user_input))}

RESPOND using SDAF methodology IN SAME LANGUAGE with systematic analysis:"""
            else:
                full_prompt = f"""
You are an OfficeAI assistant for Word and Excel automation. Strategy:

Target Model: {target_model_info['name']}
Prompt Style: {target_model_info['prompt_style']}

1. App Selection: Use "0=Word, 1=Excel" format
2. Task Categories:
   - Content generation â†’ Word + content details (adjust detail based on target model)
   - Function operations â†’ Generate VBA prompt requirements (adjust detail based on target model)
   - Direct commands â†’ Specific UI steps

Rules:
- CRITICAL: Respond in SAME LANGUAGE as current request (Chineseâ†’Chinese, Englishâ†’English)
- Keep responses very short (1-2 lines max)
- Adjust detail level for target model: {self.target_model_type} model needs {target_model_info['max_detail']} detail
- For content tasks â†’ focus on Word + content prompts
- For functional tasks â†’ create prompts for VBA generation (DO NOT write VBA code)

{context}
Current request: {user_input}

Response IN SAME LANGUAGE with appropriate detail level for {self.target_model_type} model:"""

            # Try configured AI service (OpenAI/DeepSeek/Ollama)
            if self.ai_service.is_available():
                try:
                    result = await self.ai_service.process_message(full_prompt)
                    if result:
                        # Validate information preservation
                        if self._validate_information_preservation(user_input, result):
                            self.add_to_history("assistant", result)
                            return result
                        else:
                            # Information loss detected, enhance with fallback
                            print(f"âš ï¸  Information loss detected in AI response, enhancing...")
                            fallback_result = self._generate_smart_response(user_input)
                            enhanced_result = f"{result}\\n\\nğŸ“ Enhanced context: {fallback_result}"
                            self.add_to_history("assistant", enhanced_result)
                            return enhanced_result
                except Exception as ai_error:
                    # Log AI error but continue to fallback
                    print(f"âš ï¸  AI service error, using fallback: {ai_error}")
            
            # Fallback to smart mock if AI service unavailable or failed
            result = self._generate_smart_response(user_input)
            self.add_to_history("assistant", result)
            return result
            
        except Exception as e:
            return f"Error: {e}"
    
    def _generate_smart_response(self, user_input: str) -> str:
        """Generate smart mock response with enhanced context preservation."""
        user_lower = user_input.lower()
        is_chinese = any('\u4e00' <= char <= '\u9fff' for char in user_input)
        
        # Preserve user intent by including their exact request in the response
        # This ensures no information is lost even in fallback mode
        
        # Handle model selection commands
        if user_input.lower() in ['/mb', '/model-big']:
            return self.set_target_model("big")
        
        if user_input.lower() in ['/ms', '/model-small']:
            return self.set_target_model("small")
        
        # Handle clear command
        if user_input.lower() in ['/c', '/clear']:
            return self.clear_conversation()
        
        # App selection (0/1) is now handled earlier in optimize_prompt, so this should not be reached
        
        # Get capability recommendation for the task
        capability = self.get_capability_recommendation(user_input)
        
        # Generate response based on capability and task type
        return self._generate_capability_based_response(user_input, capability, is_chinese)
    
    def _generate_capability_based_response(self, user_input: str, capability: CapabilityRecommendation, is_chinese: bool) -> str:
        """Generate response based on capability analysis with preserved user context."""
        user_lower = user_input.lower()
        
        # Create a prefix that includes the user's original request to preserve context
        user_task_prefix = f"Task: '{user_input}'\\n\\n" if len(user_input) < 100 else f"Task: '{user_input[:97]}...'\\n\\n"
        
        # Content generation tasks
        content_keywords = ["write", "generate", "create content", "draft", "letter", "report", "document", 
                           "å†™", "ç”Ÿæˆ", "åˆ›å»º", "æ–‡æ¡£", "ä¿¡ä»¶", "æŠ¥å‘Š", "èµ·è‰"]
        if any(word in user_lower for word in content_keywords):
            if is_chinese:
                if capability.recommendation == "AI":
                    base_msg = "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nâœ…AIä¼˜åŠ¿ä»»åŠ¡ï¼šå†…å®¹åˆ›ä½œ"
                    if self.target_model_type == "small":
                        return f"{user_task_prefix}{base_msg}\\néœ€è¦è¯¦ç»†æç¤ºï¼šå…·ä½“ä¸»é¢˜ã€å­—æ•°è¦æ±‚ã€æ ¼å¼è§„èŒƒã€ç›®æ ‡å—ä¼—"
                    else:
                        return f"{user_task_prefix}{base_msg}\\nç®€è¦æè¿°ä¸»é¢˜å’Œç±»å‹å³å¯"
                else:
                    return f"{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nå†…å®¹ç”Ÿæˆâ†’Wordï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚"
            else:
                if capability.recommendation == "AI":
                    base_msg = "App: 0=Word, 1=Excel\\nâœ…AI Strength: Content creation"
                    if self.target_model_type == "small":
                        return f"{user_task_prefix}{base_msg}\\nNeed detailed prompt: specific topic, word count, format specs, target audience"
                    else:
                        return f"{user_task_prefix}{base_msg}\\nBrief topic and type description sufficient"
                else:
                    return f"{user_task_prefix}App: 0=Word, 1=Excel\\nContent generation â†’ Word. Provide more details"
        
        # Specific data processing tasks (ID card, birthday, age calculation, text splitting)
        data_keywords = ["èº«ä»½è¯", "ç”Ÿæ—¥", "å¹´é¾„", "æå–", "è®¡ç®—", "å‡ºç”Ÿ", "æ‹†åˆ†", "åˆ†ç¦»", "åˆ†å‰²", "å§“å", "ç”µè¯", 
                         "ID card", "birthday", "age", "extract", "calculate", "split", "separate", "name", "phone"]
        if any(word in user_lower for word in data_keywords):
            if is_chinese:
                if "èº«ä»½è¯" in user_lower and ("ç”Ÿæ—¥" in user_lower or "å¹´é¾„" in user_lower):
                    return f"åº”ç”¨é€‰æ‹©ï¼š1=Excel\\nğŸ”§VBAè§£å†³æ–¹æ¡ˆï¼šæ•°æ®æå–å’Œè®¡ç®—\\n\\nä½¿ç”¨MIDå‡½æ•°æå–èº«ä»½è¯ä¸­çš„å‡ºç”Ÿæ—¥æœŸï¼š\\n=MID(A2,7,8) ç„¶åæ ¼å¼åŒ–ä¸º å¹´/æœˆ/æ—¥\\nè®¡ç®—å¹´é¾„ï¼š=DATEDIF(ç”Ÿæ—¥åˆ—,TODAY(),\"Y\")\\n\\né€‚åˆExcelè‡ªåŠ¨åŒ–å¤„ç†ï¼Œæ‰¹é‡æ“ä½œæ•ˆç‡é«˜"
                elif "æ‹†åˆ†" in user_lower or "åˆ†ç¦»" in user_lower or "åˆ†å‰²" in user_lower:
                    if "å§“å" in user_lower or "ç”µè¯" in user_lower:
                        return f"åº”ç”¨é€‰æ‹©ï¼š1=Excel\\nğŸ”§VBAè§£å†³æ–¹æ¡ˆï¼šæ–‡æœ¬æ‹†åˆ†\\n\\nä½¿ç”¨Excelå‡½æ•°åˆ†ç¦»æ•°æ®ï¼š\\næ–¹æ³•1ï¼šæ•°æ®â†’åˆ†åˆ—â†’æŒ‰åˆ†éš”ç¬¦åˆ†å‰²\\næ–¹æ³•2ï¼šå…¬å¼ =LEFT(B2,FIND(\" \",B2)-1) æå–å§“å\\næ–¹æ³•3ï¼šå…¬å¼ =RIGHT(B2,LEN(B2)-FIND(\" \",B2)) æå–ç”µè¯\\n\\næ‰¹é‡æ“ä½œæ•ˆç‡é«˜ï¼Œé€‚åˆå¤§é‡æ•°æ®å¤„ç†"
                    else:
                        return f"åº”ç”¨é€‰æ‹©ï¼š1=Excel\\nğŸ”§VBAè§£å†³æ–¹æ¡ˆï¼šæ–‡æœ¬æ‹†åˆ†\\n\\nä½¿ç”¨åˆ†åˆ—åŠŸèƒ½æˆ–æ–‡æœ¬å‡½æ•°è¿›è¡Œæ•°æ®åˆ†ç¦»\\nè¯·æ˜ç¡®åˆ†éš”ç¬¦ç±»å‹ï¼ˆç©ºæ ¼/é€—å·/å…¶ä»–ï¼‰"
            else:
                if "id card" in user_lower and ("birthday" in user_lower or "age" in user_lower):
                    return f"App: 1=Excel\\nğŸ”§VBA Solution: Data extraction and calculation\\n\\nUse MID function to extract birth date from ID card:\\n=MID(A2,7,8) then format as YYYY/MM/DD\\nCalculate age: =DATEDIF(birthday_column,TODAY(),\"Y\")\\n\\nSuitable for Excel automation, efficient for batch processing"
                elif "split" in user_lower or "separate" in user_lower:
                    return f"App: 1=Excel\\nğŸ”§VBA Solution: Text splitting\\n\\nUse Excel functions to separate data:\\nMethod 1: Dataâ†’Text to Columnsâ†’Delimiter\\nMethod 2: Formula =LEFT(B2,FIND(\" \",B2)-1) for first part\\nMethod 3: Formula =RIGHT(B2,LEN(B2)-FIND(\" \",B2)) for second part\\n\\nEfficient for batch processing"
        
        # VBA/Automation tasks
        automation_keywords = ["automate", "macro", "vba", "batch", "format all", "process", "convert",
                              "è‡ªåŠ¨åŒ–", "å®", "æ‰¹å¤„ç†", "å¤„ç†", "è½¬æ¢", "æ ¼å¼åŒ–"]
        if any(word in user_lower for word in automation_keywords):
            if is_chinese:
                if capability.recommendation == "VBA":
                    base_msg = "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”§VBAä¼˜åŠ¿ä»»åŠ¡ï¼šç²¾ç¡®æ“ä½œ/æ‰¹é‡å¤„ç†"
                    if self.target_model_type == "small":
                        return f"{base_msg}\\néœ€è¦è¯¦ç»†éœ€æ±‚ï¼šå…·ä½“å¯¹è±¡(æ–‡ä»¶/å•å…ƒæ ¼)ã€æ“ä½œæ¡ä»¶ã€é”™è¯¯å¤„ç†ã€é¢„æœŸç»“æœ"
                    else:
                        return f"{base_msg}\\næè¿°è‡ªåŠ¨åŒ–ç›®æ ‡å’Œä¸»è¦æ­¥éª¤å³å¯"
                elif capability.recommendation == "AI":
                    return "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nâœ…AIä¼˜åŠ¿ä»»åŠ¡ï¼šæ–‡æœ¬å¤„ç†\\nç®€è¦æè¿°å¤„ç†éœ€æ±‚å³å¯"
                else:  # HYBRID
                    return "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”€æ··åˆæ–¹æ¡ˆï¼šAIå¤„ç†å†…å®¹ + VBAæ‰§è¡Œæ“ä½œ\\nè¯·æè¿°å…·ä½“ä»»åŠ¡ä»¥ç¡®å®šæœ€ä½³æ–¹æ¡ˆ"
            else:
                if capability.recommendation == "VBA":
                    base_msg = "App: 0=Word, 1=Excel\\nğŸ”§VBA Strength: Precise operations/batch processing"
                    if self.target_model_type == "small":
                        return f"{base_msg}\\nNeed detailed requirements: specific objects (files/cells), conditions, error handling, expected results"
                    else:
                        return f"{base_msg}\\nDescribe automation goal and main steps"
                elif capability.recommendation == "AI":
                    return "App: 0=Word, 1=Excel\\nâœ…AI Strength: Text processing\\nBrief description of processing needs sufficient"
                else:  # HYBRID
                    return "App: 0=Word, 1=Excel\\nğŸ”€Hybrid approach: AI for content + VBA for execution\\nDescribe specific task to determine best approach"
        
        # Default capability-based recommendation with Structured Data Analysis Framework
        if capability.recommendation == "FUZZY_AI":
            if is_chinese:
                return f"""{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel
ğŸ§  ç»“æ„åŒ–æ•°æ®åˆ†ææ¡†æ¶(SDAF)æ¨¡å¼ï¼š{capability.reason}

ğŸ“‹ è¯·æŒ‰ä»¥ä¸‹ç³»ç»ŸåŒ–æµç¨‹è¿›è¡Œï¼š

ğŸ” é˜¶æ®µ1ï¼šæ•°æ®å‘ç°ä¸è¯„ä¼°
- åˆ†ææ•°æ®æ ¼å¼å’Œç»“æ„ï¼ˆExcelã€CSVã€æ–‡æœ¬ã€æ··åˆï¼‰
- è¯†åˆ«æ•°æ®ç±»å‹å’Œä¸ä¸€è‡´æ€§
- è¯„ä¼°å¤æ‚ç¨‹åº¦ï¼ˆç®€å•/ä¸­ç­‰/å¤æ‚/æ¨¡ç³Šï¼‰

ğŸ¯ é˜¶æ®µ2ï¼šå¤„ç†ç­–ç•¥è®¾è®¡  
- é€‰æ‹©å¤„ç†æ–¹æ³•ï¼ˆç›´æ¥è‡ªåŠ¨åŒ–/AIæ¨ç†/æ··åˆæ–¹å¼ï¼‰
- åˆ¶å®šæ–‡æœ¬å¤„ç†ç­–ç•¥ï¼ˆç»“æ„åŒ–/åŠç»“æ„åŒ–/éç»“æ„åŒ–ï¼‰

âš™ï¸ é˜¶æ®µ3ï¼šå®æ–½æŒ‡å¯¼
- è¯»å–è§£æï¼šæ ·æœ¬æ•°æ®ï¼Œè¯†åˆ«è¾¹ç•Œæƒ…å†µ
- å¤„ç†è½¬æ¢ï¼šåº”ç”¨è§„åˆ™ï¼ŒAIæ¨ç†å¤„ç†æ­§ä¹‰
- è¾“å‡ºéªŒè¯ï¼šæ ¼å¼åŒ–ç»“æœï¼Œæ•°æ®å®Œæ•´æ€§æ£€æŸ¥

ğŸ“ é˜¶æ®µ4ï¼šä¸“é—¨æ–‡æœ¬å¤„ç†
- å§“å/è”ç³»äººï¼šå¤„ç†å„ç§æ ¼å¼å’Œæ–‡åŒ–å·®å¼‚
- åœ°å€æ•°æ®ï¼šè§£æä¸åŒæ ¼å¼ï¼Œå¤„ç†ç¼©å†™
- æ··åˆå†…å®¹ï¼šåˆ†ç¦»ç»“æ„åŒ–å’Œéç»“æ„åŒ–éƒ¨åˆ†
- ä¸ä¸€è‡´æ•°æ®ï¼šä½¿ç”¨ä¸Šä¸‹æ–‡çº¿ç´¢ï¼Œæ¨¡ç³ŠåŒ¹é…

ğŸ’¡ è¯·è¯¦ç»†æè¿°ï¼š
1. æ•°æ®çš„å…·ä½“ç‰¹ç‚¹å’Œç»“æ„
2. æœŸæœ›çš„å¤„ç†ç»“æœ
3. é‡åˆ°çš„å…·ä½“é—®é¢˜æˆ–æŒ‘æˆ˜

{self._get_domain_specific_guidance(capability.reason, True)}"""
            
            domain_guidance = self._get_domain_specific_guidance(capability.reason, False)
            return f"""{user_task_prefix}App: 0=Word, 1=Excel
ğŸ§  Structured Data Analysis Framework (SDAF) Mode: {capability.reason}

ğŸ“‹ Follow this systematic workflow:

ğŸ” PHASE 1: Data Discovery & Assessment
- Analyze data format and structure (Excel, CSV, text, mixed)
- Identify data types and inconsistencies
- Assess complexity level (simple/medium/complex/fuzzy)

ğŸ¯ PHASE 2: Processing Strategy Design
- Choose processing approach (direct automation/AI reasoning/hybrid)
- Develop text processing strategy (structured/semi-structured/unstructured)

âš™ï¸ PHASE 3: Implementation Guidance  
- Read & Parse: Sample data, identify edge cases
- Process & Transform: Apply rules, use AI reasoning for ambiguity
- Output & Verify: Format results, check data integrity

ğŸ“ PHASE 4: Specialized Text Handling
- Name/Contact: Handle various formats and cultural variations
- Address Data: Parse different formats, handle abbreviations  
- Mixed Content: Separate structured and unstructured parts
- Inconsistent Data: Use context clues, fuzzy matching

ğŸ’¡ Please describe in detail:
1. Specific data characteristics and structure
2. Expected processing outcomes
3. Specific problems or challenges encountered

{domain_guidance}"""
        elif capability.recommendation == "AI":
            if is_chinese:
                return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nâœ…AIä¼˜åŠ¿ä»»åŠ¡ï¼š{capability.reason}\\nä»»åŠ¡ï¼š'{user_input}'"
            return f"App: 0=Word, 1=Excel\\nâœ…AI Strength: {capability.reason}\\nTask: '{user_input}'"
        elif capability.recommendation == "VBA":
            if is_chinese:
                return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”§VBAä¼˜åŠ¿ä»»åŠ¡ï¼š{capability.reason}\\nä»»åŠ¡ï¼š'{user_input}'"
            return f"App: 0=Word, 1=Excel\\nğŸ”§VBA Strength: {capability.reason}\\nTask: '{user_input}'"
        elif capability.recommendation == "HYBRID":
            # Enhanced HYBRID handling - provide intelligent recommendations instead of asking for more details
            hybrid_analysis = self._analyze_hybrid_task(user_input, capability, is_chinese)
            return hybrid_analysis
        
        # Default fallback
        if is_chinese:
            return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nä»»åŠ¡ï¼š'{user_input}'"
        return f"App: 0=Word, 1=Excel\\nTask: '{user_input}'"