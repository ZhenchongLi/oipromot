"""
Main prompt optimization service combining all AI capabilities.
"""

from typing import Optional, Dict, Any, List
from .capability_analyzer import CapabilityAnalyzer
from ..core.models import CapabilityRecommendation
from ..services.ai_service import AIService


class PromptOptimizer:
    """Main service for optimizing Office automation prompts."""
    
    def __init__(self, target_model_type: str = "big"):
        self.ai_service = AIService()
        self.analyzer = CapabilityAnalyzer()
        self.target_model_type = target_model_type
        self.conversation_history: List[Dict[str, str]] = []
        
        # Target model capabilities
        self.model_types = {
            "big": {
                "name": "Big Model (GPT-4, Claude-3.5, etc.)",
                "prompt_style": "brief, contextual, assumes good reasoning",
                "max_detail": "moderate"
            },
            "small": {
                "name": "Small Model (7B, 13B models, etc.)",
                "prompt_style": "detailed, step-by-step, explicit instructions", 
                "max_detail": "high"
            }
        }
    
    def set_target_model(self, model_type: str) -> str:
        """Set target model type and return confirmation message."""
        if model_type not in self.model_types:
            return "Invalid model type. Use 'big' or 'small'."
        
        self.target_model_type = model_type
        model_name = self.model_types[model_type]["name"]
        
        if model_type == "big":
            return f"ğŸ¤– Switched to big model mode: {model_name}\\nPrompts will be more brief, relying on model reasoning"
        else:
            return f"ğŸ¤– Switched to small model mode: {model_name}\\nPrompts will be more detailed with explicit steps"
    
    def clear_conversation(self) -> str:
        """Clear conversation history."""
        self.conversation_history = []
        return "ğŸ§¹ Conversation cleared! Starting fresh with new memory."
    
    def add_to_history(self, role: str, content: str):
        """Add message to conversation history."""
        self.conversation_history.append({"role": role, "content": content})
    
    def _extract_key_information(self, messages: List[Dict[str, str]]) -> str:
        """Extract key information from earlier messages to preserve important context."""
        key_info = []
        
        for msg in messages:
            content = msg['content'].lower()
            role = msg['role']
            
            # Extract important keywords and patterns
            if role == 'user':
                # Look for task requirements, constraints, specific needs
                if any(keyword in content for keyword in ['requirement', 'need', 'must', 'should', 'requirement']):
                    key_info.append(f"Requirement: {msg['content'][:100]}...")
                elif any(keyword in content for keyword in ['error', 'problem', 'issue', 'bug']):
                    key_info.append(f"Issue: {msg['content'][:100]}...")
                elif any(keyword in content for keyword in ['target', 'goal', 'objective', 'purpose']):
                    key_info.append(f"Goal: {msg['content'][:100]}...")
            elif role == 'assistant':
                # Look for important decisions or recommendations
                if any(keyword in content for keyword in ['recommend', 'suggest', 'solution', 'approach']):
                    key_info.append(f"Recommendation: {msg['content'][:100]}...")
        
        return "; ".join(key_info) if key_info else ""
    
    def _validate_information_preservation(self, original_input: str, optimized_response: str) -> bool:
        """Validate that optimized response preserves core information from original input."""
        original_lower = original_input.lower()
        response_lower = optimized_response.lower()
        
        # Extract key elements from original input
        key_elements = []
        
        # Check for specific tools/applications mentioned
        apps = ["word", "excel", "powerpoint", "office", "æ–‡æ¡£", "è¡¨æ ¼", "æ¼”ç¤º"]
        mentioned_apps = [app for app in apps if app in original_lower]
        key_elements.extend(mentioned_apps)
        
        # Check for action verbs (what user wants to do)
        actions = ["create", "generate", "write", "format", "calculate", "extract", "split", "convert", 
                  "automate", "batch", "process", "analyze", "åˆ›å»º", "ç”Ÿæˆ", "å†™", "æ ¼å¼", "è®¡ç®—", "æå–", 
                  "æ‹†åˆ†", "è½¬æ¢", "è‡ªåŠ¨åŒ–", "æ‰¹å¤„ç†", "å¤„ç†", "åˆ†æ"]
        mentioned_actions = [action for action in actions if action in original_lower]
        key_elements.extend(mentioned_actions)
        
        # Check for specific data types or objects
        objects = ["table", "chart", "document", "file", "data", "text", "number", "date", "image", 
                  "è¡¨æ ¼", "å›¾è¡¨", "æ–‡æ¡£", "æ–‡ä»¶", "æ•°æ®", "æ–‡æœ¬", "æ•°å­—", "æ—¥æœŸ", "å›¾ç‰‡"]
        mentioned_objects = [obj for obj in objects if obj in original_lower]
        key_elements.extend(mentioned_objects)
        
        # Check preservation rate
        if not key_elements:
            return True  # No specific elements to validate
            
        preserved_count = sum(1 for element in key_elements if element in response_lower)
        preservation_rate = preserved_count / len(key_elements)
        
        # Consider it valid if at least 70% of key elements are preserved
        return preservation_rate >= 0.7
    
    def get_capability_recommendation(self, user_input: str) -> CapabilityRecommendation:
        """Get AI vs VBA capability recommendation for the task."""
        return self.analyzer.analyze_task(user_input)
    
    async def optimize_prompt(self, user_input: str) -> str:
        """Main optimization method that returns the best response."""
        try:
            # Add user input to history
            self.add_to_history("user", user_input)
            
            # Analyze task capability to determine if it's a fuzzy AI task
            capability = self.get_capability_recommendation(user_input)
            
            # Create context-aware prompt with enhanced context preservation
            context = ""
            if len(self.conversation_history) > 1:
                context = "\\nPrevious conversation:\\n"
                # Use last 10 messages for better context preservation
                recent_messages = self.conversation_history[-10:]
                
                # If conversation is very long, include a summary of earlier context
                if len(self.conversation_history) > 10:
                    earlier_messages = self.conversation_history[:-10]
                    # Extract key information from earlier messages
                    key_info = self._extract_key_information(earlier_messages)
                    if key_info:
                        context += f"Earlier context summary: {key_info}\\n\\n"
                
                # Add recent messages with full detail
                for msg in recent_messages:
                    context += f"{msg['role']}: {msg['content']}\\n"
            
            target_model_info = self.model_types[self.target_model_type]
            
            # Special handling for fuzzy AI tasks
            if capability.recommendation == "FUZZY_AI":
                full_prompt = f"""
You are an OfficeAI assistant with advanced natural language processing capabilities for complex Office automation tasks.

SPECIAL MODE: FUZZY/INTELLIGENT PROCESSING DETECTED
Task Type: {capability.reason}
Target Model: {target_model_info['name']}

FUZZY AI INSTRUCTIONS:
- Use your natural language understanding and reasoning abilities
- Apply intelligent data cleaning, pattern recognition, and contextual processing
- Handle inconsistent, messy, or complex data that requires human-like interpretation
- Provide adaptive solutions that can handle case-by-case variations
- When data is ambiguous, use context clues and semantic understanding

1. App Selection: Use "0=Word, 1=Excel" format
2. Fuzzy Task Categories:
   - Intelligent data cleaning â†’ Use AI reasoning to standardize messy data
   - Contextual extraction â†’ Understand meaning and context, not just patterns
   - Adaptive processing â†’ Flexible solutions that adapt to data variations
   - Complex reasoning â†’ Multi-step logical processing

Rules:
- CRITICAL: Respond in SAME LANGUAGE as current request (Chineseâ†’Chinese, Englishâ†’English)
- Use your natural abilities for data understanding and processing
- Provide intelligent, context-aware solutions
- Explain your reasoning process when handling complex/ambiguous data
- Adjust detail level for target model: {self.target_model_type} model needs {target_model_info['max_detail']} detail

{context}
Current fuzzy/complex request: {user_input}

Response using AI natural abilities IN SAME LANGUAGE:"""
            else:
                full_prompt = f"""
You are an OfficeAI assistant for Word and Excel automation. Strategy:

Target Model: {target_model_info['name']}
Prompt Style: {target_model_info['prompt_style']}

1. App Selection: Use "0=Word, 1=Excel" format
2. Task Categories:
   - Content generation â†’ Word + content details (adjust detail based on target model)
   - Function operations â†’ Generate VBA prompt requirements (adjust detail based on target model)
   - Direct commands â†’ Specific UI steps

Rules:
- CRITICAL: Respond in SAME LANGUAGE as current request (Chineseâ†’Chinese, Englishâ†’English)
- Keep responses very short (1-2 lines max)
- Adjust detail level for target model: {self.target_model_type} model needs {target_model_info['max_detail']} detail
- For content tasks â†’ focus on Word + content prompts
- For functional tasks â†’ create prompts for VBA generation (DO NOT write VBA code)

{context}
Current request: {user_input}

Response IN SAME LANGUAGE with appropriate detail level for {self.target_model_type} model:"""

            # Try configured AI service (OpenAI/DeepSeek/Ollama)
            if self.ai_service.is_available():
                try:
                    result = await self.ai_service.process_message(full_prompt)
                    if result:
                        # Validate information preservation
                        if self._validate_information_preservation(user_input, result):
                            self.add_to_history("assistant", result)
                            return result
                        else:
                            # Information loss detected, enhance with fallback
                            print(f"âš ï¸  Information loss detected in AI response, enhancing...")
                            fallback_result = self._generate_smart_response(user_input)
                            enhanced_result = f"{result}\\n\\nğŸ“ Enhanced context: {fallback_result}"
                            self.add_to_history("assistant", enhanced_result)
                            return enhanced_result
                except Exception as ai_error:
                    # Log AI error but continue to fallback
                    print(f"âš ï¸  AI service error, using fallback: {ai_error}")
            
            # Fallback to smart mock if AI service unavailable or failed
            result = self._generate_smart_response(user_input)
            self.add_to_history("assistant", result)
            return result
            
        except Exception as e:
            return f"Error: {e}"
    
    def _generate_smart_response(self, user_input: str) -> str:
        """Generate smart mock response with enhanced context preservation."""
        user_lower = user_input.lower()
        is_chinese = any('\u4e00' <= char <= '\u9fff' for char in user_input)
        
        # Preserve user intent by including their exact request in the response
        # This ensures no information is lost even in fallback mode
        
        # Handle model selection commands
        if user_input.lower() in ['/mb', '/model-big']:
            return self.set_target_model("big")
        
        if user_input.lower() in ['/ms', '/model-small']:
            return self.set_target_model("small")
        
        # Handle clear command
        if user_input.lower() in ['/c', '/clear']:
            return self.clear_conversation()
        
        # Handle app selection responses (0/1)
        if user_input.strip() in ['0', '1']:
            app_name = "Word" if user_input.strip() == '0' else "Excel"
            if is_chinese:
                return f"âœ… å·²é€‰æ‹©{app_name}\\n\\nè¯·è¯¦ç»†æè¿°ä½ è¦å®Œæˆçš„å…·ä½“ä»»åŠ¡ï¼š\\n- æ•°æ®æ“ä½œè¯·æè¿°å…·ä½“æ­¥éª¤\\n- å†…å®¹åˆ›ä½œè¯·è¯´æ˜ä¸»é¢˜å’Œè¦æ±‚\\n- æ ¼å¼è°ƒæ•´è¯·æ˜ç¡®ç›®æ ‡æ ·å¼"
            return f"âœ… Selected {app_name}\\n\\nPlease describe your specific task in detail:\\n- For data operations: describe specific steps\\n- For content creation: specify topic and requirements\\n- For formatting: clarify target style"
        
        # Get capability recommendation for the task
        capability = self.get_capability_recommendation(user_input)
        
        # Generate response based on capability and task type
        return self._generate_capability_based_response(user_input, capability, is_chinese)
    
    def _generate_capability_based_response(self, user_input: str, capability: CapabilityRecommendation, is_chinese: bool) -> str:
        """Generate response based on capability analysis with preserved user context."""
        user_lower = user_input.lower()
        
        # Create a prefix that includes the user's original request to preserve context
        user_task_prefix = f"Task: '{user_input}'\\n\\n" if len(user_input) < 100 else f"Task: '{user_input[:97]}...'\\n\\n"
        
        # Content generation tasks
        content_keywords = ["write", "generate", "create content", "draft", "letter", "report", "document", 
                           "å†™", "ç”Ÿæˆ", "åˆ›å»º", "æ–‡æ¡£", "ä¿¡ä»¶", "æŠ¥å‘Š", "èµ·è‰"]
        if any(word in user_lower for word in content_keywords):
            if is_chinese:
                if capability.recommendation == "AI":
                    base_msg = "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nâœ…AIä¼˜åŠ¿ä»»åŠ¡ï¼šå†…å®¹åˆ›ä½œ"
                    if self.target_model_type == "small":
                        return f"{user_task_prefix}{base_msg}\\néœ€è¦è¯¦ç»†æç¤ºï¼šå…·ä½“ä¸»é¢˜ã€å­—æ•°è¦æ±‚ã€æ ¼å¼è§„èŒƒã€ç›®æ ‡å—ä¼—"
                    else:
                        return f"{user_task_prefix}{base_msg}\\nç®€è¦æè¿°ä¸»é¢˜å’Œç±»å‹å³å¯"
                else:
                    return f"{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nå†…å®¹ç”Ÿæˆâ†’Wordï¼Œè¯·æä¾›æ›´å¤šç»†èŠ‚"
            else:
                if capability.recommendation == "AI":
                    base_msg = "App: 0=Word, 1=Excel\\nâœ…AI Strength: Content creation"
                    if self.target_model_type == "small":
                        return f"{user_task_prefix}{base_msg}\\nNeed detailed prompt: specific topic, word count, format specs, target audience"
                    else:
                        return f"{user_task_prefix}{base_msg}\\nBrief topic and type description sufficient"
                else:
                    return f"{user_task_prefix}App: 0=Word, 1=Excel\\nContent generation â†’ Word. Provide more details"
        
        # Specific data processing tasks (ID card, birthday, age calculation, text splitting)
        data_keywords = ["èº«ä»½è¯", "ç”Ÿæ—¥", "å¹´é¾„", "æå–", "è®¡ç®—", "å‡ºç”Ÿ", "æ‹†åˆ†", "åˆ†ç¦»", "åˆ†å‰²", "å§“å", "ç”µè¯", 
                         "ID card", "birthday", "age", "extract", "calculate", "split", "separate", "name", "phone"]
        if any(word in user_lower for word in data_keywords):
            if is_chinese:
                if "èº«ä»½è¯" in user_lower and ("ç”Ÿæ—¥" in user_lower or "å¹´é¾„" in user_lower):
                    return f"åº”ç”¨é€‰æ‹©ï¼š1=Excel\\nğŸ”§VBAè§£å†³æ–¹æ¡ˆï¼šæ•°æ®æå–å’Œè®¡ç®—\\n\\nä½¿ç”¨MIDå‡½æ•°æå–èº«ä»½è¯ä¸­çš„å‡ºç”Ÿæ—¥æœŸï¼š\\n=MID(A2,7,8) ç„¶åæ ¼å¼åŒ–ä¸º å¹´/æœˆ/æ—¥\\nè®¡ç®—å¹´é¾„ï¼š=DATEDIF(ç”Ÿæ—¥åˆ—,TODAY(),\"Y\")\\n\\né€‚åˆExcelè‡ªåŠ¨åŒ–å¤„ç†ï¼Œæ‰¹é‡æ“ä½œæ•ˆç‡é«˜"
                elif "æ‹†åˆ†" in user_lower or "åˆ†ç¦»" in user_lower or "åˆ†å‰²" in user_lower:
                    if "å§“å" in user_lower or "ç”µè¯" in user_lower:
                        return f"åº”ç”¨é€‰æ‹©ï¼š1=Excel\\nğŸ”§VBAè§£å†³æ–¹æ¡ˆï¼šæ–‡æœ¬æ‹†åˆ†\\n\\nä½¿ç”¨Excelå‡½æ•°åˆ†ç¦»æ•°æ®ï¼š\\næ–¹æ³•1ï¼šæ•°æ®â†’åˆ†åˆ—â†’æŒ‰åˆ†éš”ç¬¦åˆ†å‰²\\næ–¹æ³•2ï¼šå…¬å¼ =LEFT(B2,FIND(\" \",B2)-1) æå–å§“å\\næ–¹æ³•3ï¼šå…¬å¼ =RIGHT(B2,LEN(B2)-FIND(\" \",B2)) æå–ç”µè¯\\n\\næ‰¹é‡æ“ä½œæ•ˆç‡é«˜ï¼Œé€‚åˆå¤§é‡æ•°æ®å¤„ç†"
                    else:
                        return f"åº”ç”¨é€‰æ‹©ï¼š1=Excel\\nğŸ”§VBAè§£å†³æ–¹æ¡ˆï¼šæ–‡æœ¬æ‹†åˆ†\\n\\nä½¿ç”¨åˆ†åˆ—åŠŸèƒ½æˆ–æ–‡æœ¬å‡½æ•°è¿›è¡Œæ•°æ®åˆ†ç¦»\\nè¯·æ˜ç¡®åˆ†éš”ç¬¦ç±»å‹ï¼ˆç©ºæ ¼/é€—å·/å…¶ä»–ï¼‰"
            else:
                if "id card" in user_lower and ("birthday" in user_lower or "age" in user_lower):
                    return f"App: 1=Excel\\nğŸ”§VBA Solution: Data extraction and calculation\\n\\nUse MID function to extract birth date from ID card:\\n=MID(A2,7,8) then format as YYYY/MM/DD\\nCalculate age: =DATEDIF(birthday_column,TODAY(),\"Y\")\\n\\nSuitable for Excel automation, efficient for batch processing"
                elif "split" in user_lower or "separate" in user_lower:
                    return f"App: 1=Excel\\nğŸ”§VBA Solution: Text splitting\\n\\nUse Excel functions to separate data:\\nMethod 1: Dataâ†’Text to Columnsâ†’Delimiter\\nMethod 2: Formula =LEFT(B2,FIND(\" \",B2)-1) for first part\\nMethod 3: Formula =RIGHT(B2,LEN(B2)-FIND(\" \",B2)) for second part\\n\\nEfficient for batch processing"
        
        # VBA/Automation tasks
        automation_keywords = ["automate", "macro", "vba", "batch", "format all", "process", "convert",
                              "è‡ªåŠ¨åŒ–", "å®", "æ‰¹å¤„ç†", "å¤„ç†", "è½¬æ¢", "æ ¼å¼åŒ–"]
        if any(word in user_lower for word in automation_keywords):
            if is_chinese:
                if capability.recommendation == "VBA":
                    base_msg = "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”§VBAä¼˜åŠ¿ä»»åŠ¡ï¼šç²¾ç¡®æ“ä½œ/æ‰¹é‡å¤„ç†"
                    if self.target_model_type == "small":
                        return f"{base_msg}\\néœ€è¦è¯¦ç»†éœ€æ±‚ï¼šå…·ä½“å¯¹è±¡(æ–‡ä»¶/å•å…ƒæ ¼)ã€æ“ä½œæ¡ä»¶ã€é”™è¯¯å¤„ç†ã€é¢„æœŸç»“æœ"
                    else:
                        return f"{base_msg}\\næè¿°è‡ªåŠ¨åŒ–ç›®æ ‡å’Œä¸»è¦æ­¥éª¤å³å¯"
                elif capability.recommendation == "AI":
                    return "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nâœ…AIä¼˜åŠ¿ä»»åŠ¡ï¼šæ–‡æœ¬å¤„ç†\\nç®€è¦æè¿°å¤„ç†éœ€æ±‚å³å¯"
                else:  # HYBRID
                    return "åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”€æ··åˆæ–¹æ¡ˆï¼šAIå¤„ç†å†…å®¹ + VBAæ‰§è¡Œæ“ä½œ\\nè¯·æè¿°å…·ä½“ä»»åŠ¡ä»¥ç¡®å®šæœ€ä½³æ–¹æ¡ˆ"
            else:
                if capability.recommendation == "VBA":
                    base_msg = "App: 0=Word, 1=Excel\\nğŸ”§VBA Strength: Precise operations/batch processing"
                    if self.target_model_type == "small":
                        return f"{base_msg}\\nNeed detailed requirements: specific objects (files/cells), conditions, error handling, expected results"
                    else:
                        return f"{base_msg}\\nDescribe automation goal and main steps"
                elif capability.recommendation == "AI":
                    return "App: 0=Word, 1=Excel\\nâœ…AI Strength: Text processing\\nBrief description of processing needs sufficient"
                else:  # HYBRID
                    return "App: 0=Word, 1=Excel\\nğŸ”€Hybrid approach: AI for content + VBA for execution\\nDescribe specific task to determine best approach"
        
        # Default capability-based recommendation
        if capability.recommendation == "FUZZY_AI":
            if is_chinese:
                return f"{user_task_prefix}åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ§ æ™ºèƒ½å¤„ç†ä»»åŠ¡ï¼š{capability.reason}\\n\\nğŸ’¡å»ºè®®ï¼šä½¿ç”¨AIçš„è‡ªç„¶èƒ½åŠ›è¿›è¡Œï¼š\\n- æ™ºèƒ½æ•°æ®æ¸…ç†å’Œæ ‡å‡†åŒ–\\n- ä¸Šä¸‹æ–‡ç†è§£å’Œå†…å®¹æå–\\n- å¤æ‚æ¨¡å¼è¯†åˆ«å’Œæ¨ç†\\n- çµæ´»é€‚åº”æ€§å¤„ç†\\n\\nè¯·è¯¦ç»†æè¿°æ•°æ®ç‰¹ç‚¹å’Œå¤„ç†éœ€æ±‚"
            return f"{user_task_prefix}App: 0=Word, 1=Excel\\nğŸ§ Intelligent Processing: {capability.reason}\\n\\nğŸ’¡Recommendation: Use AI's natural abilities for:\\n- Intelligent data cleaning and normalization\\n- Contextual understanding and content extraction\\n- Complex pattern recognition and reasoning\\n- Flexible adaptive processing\\n\\nPlease describe data characteristics and processing requirements in detail"
        elif capability.recommendation == "AI":
            if is_chinese:
                return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nâœ…AIä¼˜åŠ¿ä»»åŠ¡ï¼š{capability.reason}\\nä»»åŠ¡ï¼š'{user_input}'"
            return f"App: 0=Word, 1=Excel\\nâœ…AI Strength: {capability.reason}\\nTask: '{user_input}'"
        elif capability.recommendation == "VBA":
            if is_chinese:
                return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”§VBAä¼˜åŠ¿ä»»åŠ¡ï¼š{capability.reason}\\nä»»åŠ¡ï¼š'{user_input}'"
            return f"App: 0=Word, 1=Excel\\nğŸ”§VBA Strength: {capability.reason}\\nTask: '{user_input}'"
        elif capability.recommendation == "HYBRID":
            if is_chinese:
                return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nğŸ”€æ··åˆæ–¹æ¡ˆï¼šAI+VBA\\nä»»åŠ¡ï¼š'{user_input}'\\nè¯·æä¾›æ›´å¤šç»†èŠ‚ä»¥ç¡®å®šæœ€ä½³æ–¹æ¡ˆ"
            return f"App: 0=Word, 1=Excel\\nğŸ”€Hybrid approach: AI+VBA\\nTask: '{user_input}'\\nProvide more details to determine best approach"
        
        # Default fallback
        if is_chinese:
            return f"åº”ç”¨é€‰æ‹©ï¼š0=Word, 1=Excel\\nä»»åŠ¡ï¼š'{user_input}'"
        return f"App: 0=Word, 1=Excel\\nTask: '{user_input}'"