#!/usr/bin/env python3
"""
Core requirement optimizer logic shared between CLI and Web versions.
"""

import os
import re
import time
from typing import Optional, Dict, Any
from openai import AsyncOpenAI
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()


class RequirementOptimizer:
    """
    Core requirement optimizer that handles AI-based requirement optimization.

    This class contains the shared logic for both CLI and Web versions.
    """

    def __init__(self):
        """Initialize the optimizer with API configuration."""
        # Unified OpenAI-compatible API configuration
        api_base_url = os.getenv("API_BASE_URL", "http://localhost:11434/v1")
        if not api_base_url.endswith("/v1"):
            api_base_url = api_base_url.rstrip("/") + "/v1"

        api_key = os.getenv("API_KEY")  # None for Ollama
        self.model = os.getenv("AI_MODEL") or os.getenv("MODEL", "qwen3:1.7b")

        # Initialize OpenAI client with custom base URL
        # For Ollama, we need to provide a dummy key since OpenAI client requires it
        if api_key is None:
            api_key = "sk-no-key-required"  # Ollama ignores the key

        self.client = AsyncOpenAI(
            base_url=api_base_url,
            api_key=api_key
        )

    async def optimize_requirement(self, user_input: str) -> Dict[str, Any]:
        """
        Optimize user input to clearly describe the requirement.

        Args:
            user_input: Raw user input describing what they want

        Returns:
            Dict with result, response_time, mode, and optional error
        """
        # Get system prompt based on language and thinking mode
        system_prompt = self._get_optimization_prompt(user_input)

        # Try the configured OpenAI-compatible API
        result = await self._call_api(system_prompt, user_input)
        if result:
            return result

        # Fallback: return cleaned input
        return {
            "result": self._simple_clean(user_input),
            "response_time": 0,
            "mode": "å›žé€€æ¨¡å¼"
        }

    async def refine_requirement(self, initial_result: str, feedback: str) -> Dict[str, Any]:
        """
        Refine requirement based on user feedback.

        Args:
            initial_result: Initial AI response
            feedback: User feedback for refinement

        Returns:
            Dict with refined result, response_time, mode, and optional error
        """
        # Get refinement prompt based on language
        system_prompt = self._get_refinement_prompt(feedback)

        # Prepare user message
        is_chinese = self._detect_chinese(feedback)
        user_message = (
            f"ä¹‹å‰çš„éœ€æ±‚æè¿°ï¼š{initial_result}\nç”¨æˆ·åé¦ˆï¼š{feedback}"
            if is_chinese
            else f"Previous requirement description: {initial_result}\nUser feedback: {feedback}"
        )

        # Try the configured OpenAI-compatible API
        result = await self._call_api(system_prompt, user_message)
        if result:
            return result

        # Fallback: return initial result with feedback note
        feedback_note = f"[ç”¨æˆ·åé¦ˆ: {feedback}]" if is_chinese else f"[User feedback: {feedback}]"
        return {
            "result": f"{initial_result}\n\n{feedback_note}",
            "response_time": 0,
            "mode": "å›žé€€æ¨¡å¼"
        }

    def _get_prompt(self, text: str, mode: str = "optimization") -> str:
        """
        Get system prompt for requirement processing.

        Args:
            text: Input text to detect language
            mode: "optimization" for initial optimization, "refinement" for feedback-based refinement
        """
        is_chinese = self._detect_chinese(text)

        if mode == "optimization":
            if is_chinese:
                return """ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚åˆ†æžä¸“å®¶ï¼ŒåŒæ—¶ä¹Ÿæ˜¯Excelå’ŒWordä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†ç”¨æˆ·çš„åŽŸå§‹è¾“å…¥è½¬åŒ–ä¸ºæ¸…æ™°ã€å‡†ç¡®çš„éœ€æ±‚æè¿°ã€‚

è¦æ±‚ï¼š
1. åªæè¿°ç”¨æˆ·æƒ³è¦ä»€ä¹ˆï¼Œä¸è¦æ·»åŠ å¦‚ä½•å®žçŽ°çš„å»ºè®®
2. ä½¿ç”¨ç®€æ´ã€ä¸“ä¸šçš„è¯­è¨€
3. ä¿æŒéœ€æ±‚çš„æ ¸å¿ƒæ„å›¾
4. åŽ»é™¤å†—ä½™ä¿¡æ¯
5. ç¡®ä¿æè¿°å®Œæ•´ä¸”æ˜Žç¡®
6. å¦‚æžœæ¶‰åŠExcelæˆ–WordåŠŸèƒ½ï¼Œå‡†ç¡®ç†è§£ç›¸å…³æœ¯è¯­å’Œéœ€æ±‚
7. è¾“å‡ºç»“æžœå¿…é¡»ä»¥åˆ—è¡¨å½¢å¼å±•ç¤ºï¼Œæ¯ä¸ªéœ€æ±‚ç‚¹ç”¨æ•°å­—ç¼–å·

è¯·å°†ä»¥ä¸‹ç”¨æˆ·è¾“å…¥è½¬åŒ–ä¸ºæ¸…æ™°çš„éœ€æ±‚æè¿°ï¼š"""
            else:
                return """You are a requirement analysis expert and also an Excel and Word expert. Your task is to transform the user's raw input into a clear, accurate requirement description.

Requirements:
1. Only describe what the user wants, do not add suggestions on how to implement
2. Use concise, professional language
3. Maintain the core intent of the requirement
4. Remove redundant information
5. Ensure the description is complete and clear
6. If involving Excel or Word features, accurately understand related terms and requirements
7. Output result must be in list format, with each requirement point numbered

Please transform the following user input into a clear requirement description:"""

        elif mode == "refinement":
            if is_chinese:
                return """ä½ æ˜¯ä¸€ä¸ªéœ€æ±‚åˆ†æžä¸“å®¶ï¼ŒåŒæ—¶ä¹Ÿæ˜¯Excelå’ŒWordä¸“å®¶ã€‚æ ¹æ®ç”¨æˆ·çš„åé¦ˆï¼Œè°ƒæ•´å’Œä¼˜åŒ–ä¹‹å‰çš„éœ€æ±‚æè¿°ã€‚

è¦æ±‚ï¼š
1. æ ¹æ®ç”¨æˆ·åé¦ˆè°ƒæ•´éœ€æ±‚æè¿°
2. ä¿æŒä¸“ä¸šå’Œç®€æ´
3. ç¡®ä¿è°ƒæ•´åŽçš„æè¿°æ›´ç¬¦åˆç”¨æˆ·æ„å›¾
4. ä¸è¦æ·»åŠ å®žçŽ°å»ºè®®ï¼Œåªæè¿°éœ€æ±‚
5. å¦‚æžœæ¶‰åŠExcelæˆ–WordåŠŸèƒ½ï¼Œå‡†ç¡®ç†è§£ç›¸å…³æœ¯è¯­å’Œéœ€æ±‚
6. è¾“å‡ºç»“æžœå¿…é¡»ä»¥åˆ—è¡¨å½¢å¼å±•ç¤ºï¼Œæ¯ä¸ªéœ€æ±‚ç‚¹ç”¨æ•°å­—ç¼–å·

è¯·æä¾›è°ƒæ•´åŽçš„éœ€æ±‚æè¿°ï¼š"""
            else:
                return """You are a requirement analysis expert and also an Excel and Word expert. Based on user feedback, adjust and optimize the previous requirement description.

Requirements:
1. Adjust requirement description based on user feedback
2. Keep it professional and concise
3. Ensure the adjusted description better matches user intent
4. Do not add implementation suggestions, only describe requirements
5. If involving Excel or Word features, accurately understand related terms and requirements
6. Output result must be in list format, with each requirement point numbered

Please provide the adjusted requirement description:"""

        else:
            raise ValueError(f"Unknown mode: {mode}")

    def _get_optimization_prompt(self, user_input: str) -> str:
        """Get system prompt for requirement optimization."""
        return self._get_prompt(user_input, "optimization")

    def _get_refinement_prompt(self, feedback: str) -> str:
        """Get system prompt for requirement refinement."""
        return self._get_prompt(feedback, "refinement")

    def _detect_chinese(self, text: str) -> bool:
        """Detect if text contains Chinese characters."""
        return any('\u4e00' <= char <= '\u9fff' for char in text)

    async def _call_api(self, system_prompt: str, user_input: str) -> Optional[Dict[str, Any]]:
        """Call OpenAI-compatible API using OpenAI client with detailed error handling."""
        start_time = time.time()
        try:
            # Build the request parameters
            request_params = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                "max_tokens": 1500,
                "temperature": 0.1,
            }

            # Add enable_thinking parameter for compatibility with Qwen and other APIs
            # For non-streaming calls, it must be set to False
            request_params["extra_body"] = {"enable_thinking": False}

            # Non-streaming mode
            response = await self.client.chat.completions.create(**request_params)
            result = response.choices[0].message.content.strip()

            # Calculate response time
            response_time = time.time() - start_time

            return {
                "result": result,
                "response_time": response_time,
                "mode": "æ ‡å‡†æ¨¡å¼"
            }

        except Exception as e:
            response_time = time.time() - start_time
            error_info = self._format_error(e, response_time)


            return {
                "error": error_info["message"],
                "error_type": error_info["type"],
                "error_suggestion": error_info["suggestion"],
                "response_time": response_time
            }

    def _format_error(self, error: Exception, response_time: float) -> Dict[str, str]:
        """Format error with detailed information and suggestions."""
        error_str = str(error).lower()

        # Connection errors
        if "connection" in error_str or "timeout" in error_str or "network" in error_str:
            return {
                "type": "è¿žæŽ¥é”™è¯¯",
                "message": f"æ— æ³•è¿žæŽ¥åˆ°APIæœåŠ¡å™¨ ({self.client.base_url})",
                "suggestion": "è¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥å’ŒAPIæœåŠ¡å™¨åœ°å€é…ç½®"
            }

        # Authentication errors
        if "unauthorized" in error_str or "401" in error_str or "api key" in error_str:
            return {
                "type": "è®¤è¯é”™è¯¯",
                "message": "APIå¯†é’¥éªŒè¯å¤±è´¥",
                "suggestion": "è¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„API_KEYé…ç½®æ˜¯å¦æ­£ç¡®"
            }

        # Rate limit errors
        if "rate limit" in error_str or "429" in error_str:
            return {
                "type": "é¢‘çŽ‡é™åˆ¶",
                "message": "APIè°ƒç”¨é¢‘çŽ‡è¶…å‡ºé™åˆ¶",
                "suggestion": "è¯·ç¨ç­‰ç‰‡åˆ»åŽé‡è¯•ï¼Œæˆ–æ£€æŸ¥APIé…é¢"
            }

        # Model not found errors
        if "model" in error_str and ("not found" in error_str or "404" in error_str):
            return {
                "type": "æ¨¡åž‹é”™è¯¯",
                "message": f"æ¨¡åž‹ '{self.model}' ä¸å¯ç”¨",
                "suggestion": "è¯·æ£€æŸ¥.envæ–‡ä»¶ä¸­çš„AI_MODELé…ç½®ï¼Œç¡®ä¿æ¨¡åž‹åç§°æ­£ç¡®"
            }

        # Server errors
        if "500" in error_str or "502" in error_str or "503" in error_str:
            return {
                "type": "æœåŠ¡å™¨é”™è¯¯",
                "message": "APIæœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
                "suggestion": "æœåŠ¡å™¨æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åŽé‡è¯•"
            }

        # JSON or parsing errors
        if "json" in error_str or "parse" in error_str:
            return {
                "type": "å“åº”æ ¼å¼é”™è¯¯",
                "message": "APIå“åº”æ ¼å¼å¼‚å¸¸",
                "suggestion": "APIæœåŠ¡å¯èƒ½ä¸å…¼å®¹ï¼Œè¯·æ£€æŸ¥API_BASE_URLé…ç½®"
            }

        # Generic error
        return {
            "type": "æœªçŸ¥é”™è¯¯",
            "message": str(error),
            "suggestion": "è¯·æ£€æŸ¥ç½‘ç»œè¿žæŽ¥å’ŒAPIé…ç½®ï¼Œæˆ–è”ç³»æŠ€æœ¯æ”¯æŒ"
        }

    def _simple_clean(self, user_input: str) -> str:
        """Simple fallback cleaning when APIs are unavailable."""
        # Remove common filler words and phrases
        cleaned = user_input.strip()

        # Basic cleaning patterns
        filler_patterns = [
            "please help me", "can you help me", "i need help with",
            "i want to", "i would like to", "could you", "can you",
            "è¯·å¸®æˆ‘", "ä½ èƒ½å¸®æˆ‘", "æˆ‘æƒ³è¦", "æˆ‘éœ€è¦", "èƒ½ä¸èƒ½", "å¯ä»¥å—"
        ]

        lower_cleaned = cleaned.lower()
        for pattern in filler_patterns:
            if lower_cleaned.startswith(pattern):
                cleaned = cleaned[len(pattern):].strip()
                break

        # Capitalize first letter
        if cleaned:
            cleaned = cleaned[0].upper() + cleaned[1:]

        return cleaned


class SessionManager:
    """
    Manages optimization sessions with state tracking.

    This class handles session state for both CLI and Web versions.
    """

    def __init__(self, optimizer: RequirementOptimizer):
        """Initialize session manager with optimizer instance."""
        self.optimizer = optimizer
        self.current_requirement = ""
        self.current_feedback = ""
        self.status = "IDLE"  # IDLE, PROCESSING, WAITING_FEEDBACK, ERROR

    async def start_session(self, user_input: str) -> Dict[str, Any]:
        """
        Start a new optimization session.

        Args:
            user_input: Initial user requirement

        Returns:
            Dict with type, content, and metadata
        """
        self.current_requirement = user_input
        self.current_feedback = ""
        self.status = "PROCESSING"

        # Generate initial response
        result = await self.optimizer.optimize_requirement(user_input)

        if "error" in result:
            self.status = "ERROR"
            error_message = self._format_error_message(result)
            return {
                "type": "error",
                "content": error_message,
                "response_time": result["response_time"],
                "error_type": result.get("error_type", "æœªçŸ¥é”™è¯¯"),
                "error_suggestion": result.get("error_suggestion", "")
            }

        self.status = "WAITING_FEEDBACK"
        return {
            "type": "ai_response",
            "content": result["result"],
            "response_time": result["response_time"],
            "mode": result["mode"]
        }

    async def handle_feedback(self, feedback: str) -> Dict[str, Any]:
        """
        Handle user feedback in current session.

        Args:
            feedback: User feedback for refinement

        Returns:
            Dict with type, content, and metadata
        """
        if feedback.lower() in ['/n', 'n']:
            return self.reset_session()

        self.current_feedback = feedback
        self.status = "PROCESSING"

        # Generate refined response
        result = await self.optimizer.refine_requirement(
            self.current_requirement, feedback
        )

        if "error" in result:
            self.status = "ERROR"
            error_message = self._format_error_message(result)
            return {
                "type": "error",
                "content": error_message,
                "response_time": result["response_time"],
                "error_type": result.get("error_type", "æœªçŸ¥é”™è¯¯"),
                "error_suggestion": result.get("error_suggestion", "")
            }

        self.status = "WAITING_FEEDBACK"
        return {
            "type": "ai_response_refined",
            "content": result["result"],
            "response_time": result["response_time"],
            "mode": result["mode"]
        }

    def reset_session(self) -> Dict[str, Any]:
        """Reset current session data."""
        self.current_requirement = ""
        self.current_feedback = ""
        self.status = "IDLE"
        return {
            "type": "new_conversation",
            "content": "å¼€å§‹æ–°å¯¹è¯"
        }

    def get_status(self) -> str:
        """Get current session status."""
        return self.status

    def _format_error_message(self, result: Dict[str, Any]) -> str:
        """Format error message with type and suggestion."""
        error_type = result.get("error_type", "é”™è¯¯")
        error_message = result.get("error", "æœªçŸ¥é”™è¯¯")
        suggestion = result.get("error_suggestion", "")

        formatted_message = f"ã€{error_type}ã€‘{error_message}"
        if suggestion:
            formatted_message += f"\n\nðŸ’¡ å»ºè®®: {suggestion}"

        return formatted_message

    async def generate_final_prompt(self) -> str:
        """
        Generate final optimized prompt based on current session.

        Returns:
            Final optimized prompt
        """
        if self.current_feedback:
            # Use refined requirement
            result = await self.optimizer.refine_requirement(
                self.current_requirement, self.current_feedback
            )
        else:
            # Use original optimized requirement
            result = await self.optimizer.optimize_requirement(self.current_requirement)

        return result.get("result", self.current_requirement)